<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<meta name="progressive" content="true" />
<meta name="allow-skip" content="true" />

<title>Lecture: Bayesian Fundamentals</title>

<!-- HEAD_CONTENT -->

<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>

<!-- taken from https://github.com/rstudio/rmarkdown/blob/67b7f5fc779e4cfdfd0f021d3d7745b6b6e17149/inst/rmd/h/default.html#L296-L362 -->
<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>
<!-- end tabsets -->


<link rel="stylesheet" href="css\learnr-theme.css" type="text/css" />

</head>

<body>



<div class="pageContent band">
<div class="bandContent page">

<div class="topics">

<div id="section-bayesian-fundamentals" class="section level2">
<h2>Bayesian Fundamentals</h2>
<div id="section-the-punchline" class="section level3">
<h3>The punchline</h3>
<blockquote>
<p><sub> In the Bayesian world the unobserved quantities are assigned
distributional properties and, therefore, become random variables in the
analysis. </sub> <br></p>
<p><sub> These distributions come in two basic flavors. If the
distribution of the unknown quantity is not conditioned on fixed data,
it is called prior distribution because it describes knowledge prior to
seeing data. </sub> <br></p>
<p><sub> Alternatively, if the distribution is conditioned on data that
we observe, it is clearly updated from the unconditioned state and,
therefore, more informed. This distribution is called posterior
distribution. […] </sub> <br></p>
<p><sub> The punchline is this: All likelihood-based models are Bayesian
models in which the prior distribution is an appropriately selected
uniform prior, and as the size of the data gets large they are identical
given any finite appropriate prior. So such empirical researchers are
really Bayesian; they just do not know it yet. </sub></p>
</blockquote>
<div style="text-align: right">
<p><sub><sup> <a
href="https://academic.oup.com/jpart/article/23/2/457/1003493">Gill, J.,
&amp; Witko, C. (2013). Bayesian analytical methods: A methodological
prescription for public administration. Journal of Public Administration
Research and Theory, 23(2), 457–494.</a> </sub></sup></p>
</div>
</div>
<div id="section-likelihood-function" class="section level3">
<h3>Likelihood function</h3>
<ul>
<li>Specification of a pdf or pmf: <span
class="math inline">\(p(\mathbf{y}|\theta)\)</span>.</li>
<li>Also called the data generating process (or the generative model)
for <span class="math inline">\(y\)</span>.</li>
<li>Logical inversion: “Which unknown <span
class="math inline">\(\theta\)</span> most likely produces the known
<span class="math inline">\(\mathbf{y}\)</span>?” <span
class="math inline">\(\rightarrow\)</span> <span
class="math inline">\(L(\theta | \mathbf{y})\)</span>.</li>
<li>The notational distinction between <span
class="math inline">\(p(\mathbf{y}|\theta)\)</span> and <span
class="math inline">\(L(\theta | \mathbf{y})\)</span> is purely
conceptual. <span class="math inline">\(p(\mathbf{y}|\theta) = L(\theta
| \mathbf{y})\)</span>.</li>
<li>We will use <span
class="math inline">\(p(\mathbf{y}|\theta)\)</span>.</li>
<li>Note that the likelihood function multiplies densities across
<em>all</em> observations; e.g., a normal likelihood function is given
by:</li>
</ul>
<p><span class="math display">\[p(\mathbf{y}|\mu, \sigma) =
\prod_{i=1}^{N} \frac{1}{\sigma \sqrt{2 \pi}} \exp\left(- 0.5 \left(
(y_i - \mu_i)^2 / \sigma \right) \right)\]</span></p>
<ul>
<li>This is what we mean mathematically when we use the shorthand
<ul>
<li><span class="math inline">\(\mathbf{y} \sim \text{N}(\mu,
\sigma)\)</span> or</li>
<li><span class="math inline">\(y_i \sim \text{N}(\mu_i, \sigma) \text{
for all } i=1,...N\)</span>.</li>
</ul></li>
</ul>
</div>
<div id="section-prior-distribution" class="section level3">
<h3>Prior distribution</h3>
<ul>
<li>A distributional characterization of our belief about an unknown
quantity (i.e., a parameter) prior to seeing the data: <span
class="math inline">\(p(\theta)\)</span></li>
<li>This includes statements about <em>family</em>, <em>support</em>,
and <em>density</em>.
<ul>
<li><em>Family</em>: A pdf (continuous parameters) or pmf (discrete
parameters) that can plausibly generate the parameter values.</li>
<li><em>Support</em>: Some parameters have constrained support:
Probability parameters must be inside <span class="math inline">\([0,
1]\)</span>; variance parameters must be <span
class="math inline">\(\geq 0\)</span>.</li>
<li><em>Density</em>: A distributional characterization which values of
the parameter we think are more or less likely to observe.</li>
</ul></li>
<li>The prior distribution can be
<ul>
<li>flat (i.e., uniformly distributed over the supported range – often
improper)</li>
<li>purposefully very vague, and thus, rather uninformative</li>
<li>weakly informative</li>
<li>specific and substantively informed (e.g., by previous research or
expert assessment)</li>
</ul></li>
</ul>
</div>
<div id="section-posterior-distribution" class="section level3">
<h3>Posterior distribution</h3>
<ul>
<li>Updating our distributional belief about <span
class="math inline">\(\theta\)</span> given the data, <span
class="math inline">\(\mathbf{y}\)</span>: <span
class="math inline">\(p(\theta | \mathbf{y})\)</span></li>
<li>Follows the proportional version of <a
href="https://en.wikipedia.org/wiki/Bayes%27_theorem">Bayes’ Law</a>:
<span class="math inline">\(p(\theta | \mathbf{y}) \propto p(\theta)
\times p(\mathbf{y}|\theta)\)</span></li>
<li>Yields a weighthed combination of likelihood and prior</li>
<li>The prior pulls the posterior density toward the center of gravity
of the prior distribution</li>
<li>As the data grows large, the likelihood becomes more influential:
<ul>
<li>one factor for <span class="math inline">\(p(\theta)\)</span>, <span
class="math inline">\(N\)</span> factors for <span
class="math inline">\(p(y_i|\theta_i)\)</span></li>
<li>we will see this analytically and using simulations later on</li>
</ul></li>
</ul>
</div>
</div>
<div id="section-coin-flip-experiment" class="section level2">
<h2>Coin flip experiment</h2>
<div id="section-the-experiment" class="section level3">
<h3>The experiment</h3>
<p>Suppose we flip a coin up to <span class="math inline">\(N\)</span>
times:</p>
<ul>
<li>The fairness of a coin can be expressed through a <em>probability
parameter</em>, <span class="math inline">\(\pi\)</span>, that governs
the probability that a coin flip produces heads (1) has opposed to tails
(0)</li>
<li>We start out with the belief that the coin is fair – that is, we
consider it more probable that the coin is fair (<span
class="math inline">\(\pi \approx 0.5\)</span>) and less probable that
it systematically over-produces either heads or tails</li>
<li>Unbeknownst to us, the coin is far from fair – it is 4 times as
likely to produce heads as it is to produce tails (that is, <span
class="math inline">\(\pi=0.8\)</span>)</li>
<li>We slowly learn about this in the process of flipping the coin and
keeping score of the number of flips <span
class="math inline">\(n\)</span> and the number of heads <span
class="math inline">\(k\)</span>…</li>
</ul>
</div>
<div id="section-analytical-form-prior-distribution"
class="section level3">
<h3>Analytical form: Prior distribution</h3>
<ul>
<li>The <em>beta distribution</em> is a suitable candidate for
characterizing our prior beliefs: <span class="math inline">\(\pi \sim
\text{beta}(a,b)\)</span></li>
<li>Characterized by two shape parameters, <span
class="math inline">\(a\)</span> and <span
class="math inline">\(b\)</span></li>
<li><span class="math inline">\(a\)</span> and <span
class="math inline">\(b\)</span> are <em>hyperparameters</em>: Known (or
chosen) arameters that characterize a prior distribution.</li>
<li>Constrained support: <span class="math inline">\(\pi \in [0,
1]\)</span></li>
<li>pdf: <span class="math inline">\(p(\pi) = \frac{\pi^{a-1} (1-
\pi)^{b-1}}{\text{B}(a, b)}\)</span></li>
</ul>
<p><img src="03-lec_files/figure-html/beta-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
<div id="section-analytical-form-likelihood" class="section level3">
<h3>Analytical form: Likelihood</h3>
<ul>
<li>Flipping one and the same coin <span
class="math inline">\(n\)</span> times is a series of Bernoulli
trials</li>
<li>The <em>binomial distribution</em> describes the corresponding data
generating process: <span class="math inline">\(k \sim
\text{Binomial}(n, \pi)\)</span></li>
<li>pmf: <span class="math inline">\(p(k|n, \pi) = {n \choose k} \pi^k
(1-\pi)^{(n-k)}\)</span></li>
</ul>
</div>
<div id="section-analytical-form-posterior-distribution"
class="section level3">
<h3>Analytical form: Posterior distribution</h3>
<p>Remember: <span class="math display">\[p(\theta | \mathbf{y}) \propto
p(\theta) \times p(\mathbf{y}|\theta)\]</span></p>
<p>So what does this mean in the present example?</p>
<p><span class="math display">\[\begin{split}p(\pi|n,k) &amp; \propto
p(\pi) \times p(k|n, \pi) \\
p(\pi|n,k) &amp; \propto \frac{\pi^{a-1} (1- \pi)^{b-1}}{\text{B}(a, b)}
\times {n \choose k} \pi^k (1-\pi)^{(n-k)}\end{split}\]</span></p>
<p>Note that since we use the proportional version of Bayes’ Law (i.e.,
we do not stipulate exact equality), we can drop any constant terms that
do not involve our parameter of interest, <span
class="math inline">\(\pi\)</span>:</p>
<p><span class="math display">\[\begin{split}p(\pi|n,k) &amp; \propto
\pi^{a-1} (1- \pi)^{b-1} \times \pi^k
(1-\pi)^{(n-k)}\end{split}\]</span> The rest, then, is easy: Following
the rules of exponentiation, we add exponents for identical bases. This
gives us our posterior distribution for <span
class="math inline">\(\pi\)</span>:</p>
<p><span class="math display">\[\begin{split}p(\pi|n,k) &amp; \propto
\pi^{a+k-1} (1- \pi)^{b+n-k-1}\end{split}\]</span> As you see, our
posterior has the exact same form as our prior. It is a beta
distribution with updated parameters</p>
<ul>
<li><span class="math inline">\(a^{\prime} = a+k-1\)</span></li>
<li><span class="math inline">\(b^{\prime} = b+n-k-1\)</span></li>
</ul>
<p>This property is called <em>conjugacy</em>: Prior and posterior are
of the same family.</p>
<p>Now, take a moment to think about our analytical solution for the
updated parameter:</p>
<ul>
<li>What does it take for the data to dominate the prior?</li>
<li>What if the prior is weak (e.g., <span class="math inline">\(\pi
\sim \text{beta}(1,1)\)</span>)?</li>
<li>What if the prior is strong (e.g., <span class="math inline">\(\pi
\sim \text{beta}(100,100)\)</span>)?</li>
</ul>
</div>
<div id="section-simulation" class="section level3">
<h3>Simulation</h3>
<div id="section-prior-distribution-1" class="section level4">
<h4>Prior distribution</h4>
<details>
<summary>
Code: Defining and plotting the prior distribution
</summary>
<pre class="r"><code>len_pi &lt;- 1001L                      ### number of candidate values for pi
pi &lt;- seq(0, 1, length.out = len_pi) ### candidate values for pi
a &lt;- b &lt;- 5                          ### hyperparameters
prior &lt;- dbeta(pi, a, b)             ### prior distribution

## Plot
plot(                                ### set up empty plot, specify labels
  pi, prior,
  type = &#39;n&#39;,
  xlab = &quot;Density&quot;,
  ylab = expression(paste(&quot;Prior Distribution for &quot;, pi))
)
polygon(                             ### draw density distribution
  c(rep(0, length(pi)), pi),
  c(prior, rev(prior)),
  col = adjustcolor(&#39;red&#39;, alpha.f = .4),
  border = NA
)
abline(                              ### add vertical at pi = 0.5 
  v = .5,
  col = &#39;white&#39;
)</code></pre>
</details>
<p><img src="03-lec_files/figure-html/coin-sim0-print-1.png" width="75%" style="display: block; margin: auto;" /></p>
</div>
<div id="section-posterior-distribution-1" class="section level4">
<h4>Posterior distribution</h4>
<details>
<summary>
Code: Simulating the experiment
</summary>
<pre class="r"><code>set.seed(20210329)                   ### set seed for replicability
len_pi &lt;- 1001L                      ### number of candidate values for pi
pi &lt;- seq(0, 1, length.out = len_pi) ### candidate values for pi
a &lt;- b &lt;- 5                          ### hyperparameters
n &lt;- 300                             ### num. of coin flips
pi_true &lt;- .8                        ### true parameter
data &lt;- rbinom(n, 1, pi_true)        ### n coin flips
posterior &lt;- matrix(NA, 3L, n)       ### matrix container for posterior

for (i in seq_len(n)) {    
  current_sequence &lt;- data[1:i]      ### sequence up until ith draw
  k &lt;- sum(current_sequence)         ### number of heads in current sequence
  
  ##### Updating
  a_prime &lt;- a + k               
  b_prime &lt;- b + i - k
  
  ### Analytical means and credible intervals
  posterior[1, i] &lt;- a_prime / (a_prime + b_prime)
  posterior[2, i] &lt;- qbeta(0.025, a_prime, b_prime)
  posterior[3, i] &lt;- qbeta(0.975, a_prime, b_prime)
}

## Plot
plot(                                ### set up empty plot with labels
  1:n, 1:n,
  type = &#39;n&#39;,
  xlab = &quot;Number of Coin Flips&quot;,
  ylab = expression(paste(&quot;Posterior Means of &quot;,
                          pi,
                          sep = &quot; &quot;)), 
  ylim = c(0, 1),
  xlim = c(1, n)
)
abline(                              ### reference line for the true pi
  h = c(.5, .8),
  col = &quot;gray80&quot;
)
rect(-.5, qbeta(0.025, 5, 5),        ### prior mean + interval at i = 0
     0.5, qbeta(0.975, 5, 5),
     col = adjustcolor(&#39;red&#39;, .4),
     border = adjustcolor(&#39;red&#39;, .2))
segments(-.5, .5,
         0.5, .5,
         col = adjustcolor(&#39;red&#39;, .9),
         lwd = 1.5)
polygon(                             ### posterior means + intervals
  c(seq_len(n), rev(seq_len(n))),
  c(posterior[2, ], rev(posterior[3, ])),
  col = adjustcolor(&#39;blue&#39;, .4),
  border = adjustcolor(&#39;blue&#39;, .2)
)
lines(
  seq_len(n),
  posterior[1, ],
  col = adjustcolor(&#39;blue&#39;, .9),
  lwd = 1.5
)</code></pre>
</details>
<p><img src="03-lec_files/figure-html/coin-sim2-1.png" width="75%" style="display: block; margin: auto;" /></p>
<p><em>Note:</em> After 300 coin flips, we have observed 241 heads,
which is a proportion of 0.803. The posterior median is 0.794; the 95%
credible interval is [0.747, 0.837].</p>
</div>
</div>
</div>
<div id="section-mcmc-algorithms" class="section level2">
<h2>MCMC algorithms</h2>
<div id="section-analytical-classical-bayesian-inference"
class="section level3">
<h3>Analytical (classical) Bayesian inference</h3>
<ul>
<li>As you may have noticed: Our coin flip example did <em>not</em>
involve <em>any</em> numerical estimation algorithms.</li>
<li>We simply observed the data, applied Bayes’ Law, and analytically
updated our parameters.</li>
<li>This allowed us to retrieve a distributional characterization of our
parameter of interest at each iteration of the coin flip series.</li>
<li>The reasons why we could do this with ease is that this simple
Binomial problem involved a single parameter <span
class="math inline">\(\pi\)</span>; i.e, we were dealing with a
uni-dimensional <em>parameter space</em>.</li>
</ul>
</div>
<div id="section-the-limits-of-analytical-bayesian-inference"
class="section level3">
<h3>The limits of analytical Bayesian inference</h3>
<ul>
<li>Even in only slightly more intricate applications, Bayesian
inference involves finding a <em>joint</em> posterior for <em>all</em>
parameters in a model, i.e., finding a <em>multi-dimensional</em>
parameter space.</li>
<li>Inference on single parameters from a joint multi-dimensional
parameter space requires that we retrieve the marginal posterior
distribution from the joint posterior distribution.</li>
<li>Marginalizing the joint multidimensional posterior distribution
w.r.t. to a given a parameter gives the posterior distribution for that
parameter. This requires <em>integrating</em> out all other
parameters.</li>
<li>For instance, when our joint posterior in a three-dimensional
parameter space is <span class="math inline">\(p(\alpha,\beta,
\gamma)\)</span>, we need to obtain each marginal posterior akin to
<span class="math inline">\(p(\alpha) = \int_{\beta} \int_{\gamma}
p(\alpha,\beta, \gamma) d\beta d\gamma\)</span></li>
<li>For complex multi-dimensional posterior distributions, finding
analytical solutions through integration becomes cumbersome, if not
outright impossible.</li>
</ul>
</div>
<div id="section-numerical-approximation-via-mcmc"
class="section level3">
<h3>Numerical approximation via MCMC</h3>
<p>That’s where numerical approximation through Markov Chain Monte Carlo
(MCMC) algorithms comes in:</p>
<ul>
<li>MCMC are iterative computational processes that explore and describe
a posterior distribution.</li>
<li>Developed in the 1980s and popularized in the 1990s, MCMC algorithms
quickly eliminated the need for analytical marginalizations of single
parameters from joint multi-dimensional posteriors.</li>
<li>The core idea:
<ul>
<li><em>Markov Chains</em> wander through, and take samples from, the
parameter space.Following an initial warmup period, the Markov Chains
will converge to high-density regions of the underlying posterior
distribution (ergodicity).</li>
<li>The proportion of “steps” in a given region of multidimensional
parameter space gives a stochastic simulation of the posterior
probability density.</li>
<li>This yields a numerical approximation of the underlying posterior
distribution, much like Monte Carlo simulations of MLE parameters yield
numerical approximations of the underlying sampling distribution.</li>
</ul></li>
</ul>
</div>
<div id="section-some-mcmc-algorithms" class="section level3">
<h3>(Some) MCMC Algorithms</h3>
<ol style="list-style-type: decimal">
<li><strong>Gibbs</strong>: Draws iteratively and alternatively from the
conditional conjugate distribution of each parameter.</li>
<li><strong>Metropolis-Hastings</strong>: Considers a single
multidimensional move on each iteration depending on the quality of the
proposed candidate draw.</li>
<li><strong>Hamiltonian Monte Carlo (HMC)</strong>, used in Stan:</li>
</ol>
<blockquote>
<sub> The Hamiltonian Monte Carlo algorithm starts at a specified
initial set of parameters <span class="math inline">\(\theta\)</span>;
in Stan, this value is either user-specified or generated randomly.
Then, for a given number of iterations, a new momentum vector is sampled
and the current value of the parameter <span
class="math inline">\(\theta\)</span> is updated using the leapfrog
integrator with discretization time <span
class="math inline">\(\epsilon\)</span> and number of steps <span
class="math inline">\(L\)</span> according to the Hamiltonian dynamics.
Then a Metropolis acceptance step is applied, and a decision is made
whether to update to the new state <span
class="math inline">\((\theta^{\ast},\rho{\ast})\)</span> or keep the
existing state. </sub>
</blockquote>
<div style="text-align: right">
<p><sub><sup> Source: <a
href="https://mc-stan.org/docs/2_19/reference-manual/hamiltonian-monte-carlo.html">Stan
Reference Manual, Section 14.1</a> </sub></sup></p>
</div>
</div>
</div>
<div id="section-implementing-a-gibbs-sampler" class="section level2">
<h2>Implementing a Gibbs sampler</h2>
<div id="section-in-a-nutshell" class="section level3">
<h3>In a nutshell</h3>
<ul>
<li>We want to perform inference on a variable <span
class="math inline">\(y\)</span>, of which we have <span
class="math inline">\(N\)</span> observations.</li>
<li>We stipulate that the data-generating process that produces <span
class="math inline">\(y\)</span> is normal: <span
class="math inline">\(\mathbf{y} \sim \text{N}(\mu, \sigma^2)\)</span>.
This yields a two-dimensional parameter space.</li>
<li>For reasons of convenience, we parameterize the variance of this
normal distribution in terms of its precision <span
class="math inline">\(\tau = \frac{1}{\sigma^2}\)</span>, not in terms
of its standard deviation or variance.</li>
<li>Note, however, that <code>rnorm()</code> in R uses the standard
deviation, which is <code>sqrt(1 / tau)</code>.</li>
<li>We will use a <em>Gibbs sampler</em>. Remember that Gibbs draws
iteratively and alternatively from the conditional conjugate
distribution of each parameter.</li>
<li>We thus need some analytical preliminaries: Namely, analytical forms
for the posterior distributions of the two parameters from whose
marginal posteriors we would like to sample.</li>
<li>This will <em>not</em> involve marginalizing out the “unwanted”
parameters; instead, we will derive the posteriors of <span
class="math inline">\(\mu\)</span> and <span
class="math inline">\(\tau\)</span> as conditional functions of <span
class="math inline">\(\tau\)</span> and <span
class="math inline">\(\mu\)</span>, respectively</li>
</ul>
</div>
<div id="section-application" class="section level3">
<h3>Application</h3>
<ul>
<li>Specifically, we will focus on the variable <code>sup_afd</code>
from the data set <code>gles</code>.</li>
<li>Let’s pretend our prior belief is completely naive:
<ul>
<li>We don’t know how (un)popular the AfD is in the German
electorate</li>
<li>But we know that individual support is measured on a -5 to 5
scale</li>
<li>Our prior belief for <span class="math inline">\(\mu\)</span> should
thus be agnostic as to whether people like or dislike the AfD and
sufficiently vague to allow for the possibility that we may be wrong:
<span class="math inline">\(\mu \sim \text{N}(\theta = 0, \omega^{-1} =
10)\)</span> (mean <span class="math inline">\(\theta\)</span> and
precision <span class="math inline">\(\omega\)</span> are
hyperparameters for the prior of <span
class="math inline">\(\mu\)</span>)</li>
<li>Our prior belief for <span class="math inline">\(\tau\)</span> will
also be vague: <span class="math inline">\(\tau \sim \Gamma(\alpha = 20,
\beta = 200)\)</span> (shape <span class="math inline">\(\alpha\)</span>
and rate <span class="math inline">\(\beta\)</span> are hyperparameters
for the prior of <span class="math inline">\(\tau\)</span>)</li>
<li>We have no prior belief about the dependence of both parameters and
hence specify independent prior distributions</li>
</ul></li>
</ul>
</div>
<div id="section-analytical-preliminaries-mu" class="section level3">
<h3>Analytical preliminaries: <span
class="math inline">\(\mu\)</span></h3>
<p>Our prior belief is that <span class="math inline">\(\mu\)</span> is
distributed normal with mean <span class="math inline">\(\theta =
0\)</span> and precision <span class="math inline">\(\omega =
.1\)</span>:</p>
<p><span class="math display">\[\mu \sim \text{N}(0, 10)\]</span></p>
<p>The prior pdf is given by:</p>
<p><span class="math display">\[
p(\mu | \theta, \omega) = \sqrt{\frac{\omega}{2 \pi}} \exp \left
(-\frac{\omega (\mu - \theta)^2}{2} \right)
\]</span></p>
<p>while the likelihood for the data <span
class="math inline">\(\mathbf{y}\)</span> is given by</p>
<p><span class="math display">\[
p(\mathbf{y} | \mu, \tau) = \prod_{i}^{N} \sqrt{\frac{\tau}{2\pi}}
\exp\left(-\frac{\tau(y_i-\mu)^2}{2} \right)
\]</span></p>
<p>Multiplying prior and likelihood and performing some algebraic
transformations, we see that our conditional posterior density will
be</p>
<p><span class="math display">\[
p(\mu | \theta, \omega, \tau, \mathbf{y}) \propto \exp
\left(-\frac{\omega + N \tau}{2}  \left(\mu - \frac{\omega \theta + N
\tau \bar{y}}{\omega + N \tau}\right)^2 \right)
\]</span></p>
<p>We recognize this as the normal pdf with updated mean parameter <span
class="math inline">\(\theta^{\ast} = \frac{\omega \theta + N \tau
\bar{y}}{\omega + N \tau}\)</span> and updated precision parameter <span
class="math inline">\(\omega^{\ast} = \omega + N \tau\)</span>.</p>
<p>This gives us the required analytical solutions for the normal
parameters that characterize the posterior density of <span
class="math inline">\(\mu\)</span>.</p>
</div>
<div id="section-analytical-preliminaries-tau" class="section level3">
<h3>Analytical preliminaries: <span
class="math inline">\(\tau\)</span></h3>
<p>Furthermore, for our prior knowledge about the precision, we assume
that <span class="math inline">\(\tau\)</span> is Gamma-distributed with
shape <span class="math inline">\(\alpha=20\)</span> and rate <span
class="math inline">\(\beta = 200\)</span>: <span
class="math inline">\(\tau \sim \Gamma(20, 200)\)</span> which yields
the prior pdf:</p>
<p><span class="math display">\[
p(\tau | \alpha, \beta) =  \frac{\beta^{\alpha}}{\Gamma(\alpha)}
\tau^{\alpha - 1} \exp(-\beta \tau)
\]</span></p>
<p>while the likelihood for the data is still given by</p>
<p><span class="math display">\[
p(\mathbf{y} | \mu, \tau) = \prod_{i}^{N} \sqrt{\frac{\tau}{2\pi}}
\exp\left(-\frac{\tau(y_i-\mu)^2}{2}\right)
\]</span></p>
<p>Once again taking the product and rearranging, we find that the
conditional posterior pdf of <span class="math inline">\(\tau\)</span>
is given by</p>
<p><span class="math display">\[
p(\tau | \alpha, \beta, \mu, \mathbf{y}) \propto \tau^{\alpha +
\frac{N}{2} - 1} \exp\left(-\left(\beta + \sum_{i=1}^{N} \frac{(y_i -
\mu)^2}{2} \tau\right)\right)
\]</span></p>
<p>This is a gamma distribution with updated parameters <span
class="math inline">\(\alpha^{\ast} = \alpha + \frac{N}{2}\)</span> and
<span class="math inline">\(\beta^{\ast} = \beta + \sum_{i=1}^{N}
\frac{(x_i - \mu)^2}{2}\)</span>. Thus, we also have analytical
solutions for the Gamma parameters that characterize the posterior
density of <span class="math inline">\(\tau\)</span>.</p>
</div>
<div id="section-simulating-the-independent-prior-distributions"
class="section level3">
<h3>Simulating the independent prior distributions</h3>
<details>
<summary>
Code: Function for simulating the priors
</summary>
<pre class="r"><code># Function
draw_from_prior &lt;-
  function(theta,
           omega,
           alpha,
           beta,
           n_draws,
           seed = 20210329) {
    # Set seed
    set.seed(seed)
    
    # Take draws
    mu &lt;- rnorm(n_draws, theta, 1 / sqrt(omega))
    tau &lt;- rgamma(n_draws, alpha, beta)
    
    ## Return output
    return(list(mu = mu,
                tau = tau))
  }</code></pre>
</details>
<div class="tutorial-exercise" data-label="prior-sim"
data-caption="Code" data-completion="1" data-diagnostics="1"
data-startover="1" data-lines="20">
<pre class="text"><code># Apply function
draws_prior &lt;-
  draw_from_prior(
    theta = 0,
    omega = .1,
    alpha = 20,
    beta = 200,
    n_draws = 4000
  )

# Plots of Marginal Densities
par(mfrow = c(1, 3), oma = c(0, 0, 3, 0))
plot(density(draws_prior$mu),
     main = expression(&quot;Marginal Density of&quot; ~ mu))
plot(density(draws_prior$tau),
     main = expression(&quot;Marginal Density of&quot; ~ tau))
plot(density(1 / draws_prior$tau),
     main = expression(&quot;Marginal Density of&quot; ~ sigma^2))
title(&quot;Prior Distribution of Mean and Precision&quot;, outer = T)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":9,"fig.height":5,"fig.retina":2,"fig.align":"center","fig.keep":"high","fig.show":"asis","out.width":864,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
</div>
<div id="section-implementing-the-gibbs-sampler-for-the-posterior"
class="section level3">
<h3>Implementing the Gibbs sampler for the posterior</h3>
<details>
<summary>
Code: Gibbs sampler for the posterior
</summary>
<pre class="r"><code># Define function
draw_from_posterior &lt;- function(theta,
                                omega,
                                alpha,
                                beta,
                                n_warmup,
                                n_draws,
                                data,
                                seed = 20210329,
                                keep_warmup = TRUE) {
  # Set seed
  set.seed(seed)

  # Length of chain
  len_chain &lt;- n_warmup + n_draws
  
  # Data characteristics
  n_data &lt;- length(data)  
  mean_data &lt;- mean(data) 

  # Initialize containers
  mu &lt;- rep(NA, len_chain)
  tau &lt;- rep(NA, len_chain)
  
  # Run Gibbs sampler
  for (i in seq_len(len_chain)) {
    if (i == 1) {
      ## Iteration 1: Initialize from prior
      alpha_star &lt;- alpha
      beta_star &lt;- beta
    } else {
      ## Iterations 2+: Update alpha and beta
      alpha_star &lt;- alpha + n_data / 2
      beta_star &lt;- beta + sum(((data - mu[i - 1]) ^ 2) / 2)
    }
    
    ## Sample tau
    tau[i] &lt;- rgamma(1, alpha_star, beta_star)
    
    ## Update theta and omega
    theta_star &lt;-
      (omega * theta + n_data * tau[i] * mean_data) /
      (omega + n_data * tau[i])
    omega_star &lt;- omega + n_data * tau[i]
    
    ## Sample mu
    mu[i] &lt;- rnorm(1, theta_star, 1 / sqrt(omega_star))
  }
  
  ## Conditionally discard warmup-draws
  if (!keep_warmup) {
    tau &lt;- tau[(n_warmup + 1):len_chain]
    mu &lt;- mu[(n_warmup + 1):len_chain]
  }
  
  ## Return output
  return(list(mu = mu,
              tau = tau))
}</code></pre>
</details>
<div class="tutorial-exercise" data-label="posterior-sim"
data-caption="Code" data-completion="1" data-diagnostics="1"
data-startover="1" data-lines="30">
<pre class="text"><code># Apply function
draws_posterior &lt;-
  draw_from_posterior(
    theta = 0,
    omega = .1,
    alpha = 20,
    beta = 200,
    n_warmup = 1000,
    n_draws = 1000,
    data = gles$sup_afd,
    keep_warmup = TRUE
  )

draws_posterior_post_warmup &lt;-
  draw_from_posterior(
    theta = 0,
    omega = .1,
    alpha = 20,
    beta = 200,
    n_warmup = 1000,
    n_draws = 1000,
    data = gles$sup_afd,
    keep_warmup = FALSE
  )

# Plots of Marginal Densities and Trace Plots
par(mfrow = c(3, 2),
    oma = c(0, 0, 3, 0))

# Plot  mu
plot(
  seq_along(draws_posterior$mu),
  draws_posterior$mu,
  type = &quot;l&quot;,
  lwd = .3,
  main = expression(&quot;Trace Plot for&quot; ~ mu),
  xlab = &quot;Draws&quot;,
  ylab = expression(mu)
)
lines(predict(loess(
  draws_posterior$mu ~ seq_along(draws_posterior$mu), span = .1
)),
col = &#39;red&#39;, lwd = 1)
plot(density(draws_posterior_post_warmup$mu),
     main = expression(&quot;Marginal Density of&quot; ~ mu))

# Plot tau
plot(
  seq_along(draws_posterior$tau),
  draws_posterior$tau,
  type = &quot;l&quot;,
  lwd = .3,
  main = expression(&quot;Trace Plot for&quot; ~ tau),
  xlab = &quot;Draws&quot;,
  ylab = expression(tau)
)
lines(predict(loess(
  draws_posterior$tau ~ seq_along(draws_posterior$tau), span = .1
)),
col = &#39;red&#39;, lwd = 1)
plot(density(draws_posterior_post_warmup$tau),
     main = expression(&quot;Marginal Density of&quot; ~ tau))
title(&quot;Posterior Distribution of Mean and Precision&quot;, outer = T)

# Plot sigma^2
plot(
  seq_along(draws_posterior$tau),
  1 / draws_posterior$tau,
  type = &quot;l&quot;,
  lwd = .3,
  main = expression(&quot;Trace Plot for&quot; ~ sigma ^ 2),
  xlab = &quot;Draws&quot;,
  ylab = expression(tau)
)
lines(predict(loess(
  I(1 / draws_posterior$tau) ~ seq_along(draws_posterior$tau), span = .1)),
col = &#39;red&#39;, lwd = 1)
plot(density(1 / draws_posterior_post_warmup$tau),
     main = expression(&quot;Marginal Density of&quot; ~ sigma ^ 2))
title(&quot;Posterior Distribution of Mean and Precision&quot;, outer = T)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":9,"fig.height":9,"fig.retina":2,"fig.align":"center","fig.keep":"high","fig.show":"asis","out.width":864,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
</div>
<div id="section-how-the-sampler-explores-the-joint-posterior-density"
class="section level3">
<h3>How the sampler explores the joint posterior density</h3>
<div class="tutorial-exercise" data-label="joint-posterior"
data-caption="Code" data-completion="1" data-diagnostics="1"
data-startover="1" data-lines="30">
<pre class="text"><code># Apply function
draws_posterior &lt;-
  draw_from_posterior(
    theta = 0,
    omega = .1,
    alpha = 20,
    beta = 200,
    n_warmup = 100,
    n_draws = 1000,
    data = gles$sup_afd,
    keep_warmup = TRUE
  )

# Save as matrix, transform precision to variance
draws_posterior &lt;- simplify2array(draws_posterior)
draws_posterior[, 2] &lt;- 1 / draws_posterior[, 2]

# Plot
for (i in seq_len(nrow(draws_posterior))) {
  if (i == 1) {
    plot(
      draws_posterior[i, 1],
      draws_posterior[i, 2],
      pch = 23,
      xlim = range(draws_posterior[, 1]),
      ylim = range(draws_posterior[, 2]),
      main = &quot;Exploration of the joint posterior&quot;,
      xlab = expression(mu),
      ylab = expression(sigma ^ 2),
      col = NA,
      bg = adjustcolor(&quot;red&quot;, alpha.f = 0.25)
    )
  } else {
    segments(
      draws_posterior[i - 1, 1],
      draws_posterior[i - 1, 2],
      draws_posterior[i - 1, 1],
      draws_posterior[i, 2],
      col = adjustcolor(&quot;gray10&quot;, alpha.f = 0.05),
      lwd = 3
    )
    segments(
      draws_posterior[i - 1, 1],
      draws_posterior[i, 2],
      draws_posterior[i, 1],
      draws_posterior[i, 2],
      col = adjustcolor(&quot;gray10&quot;, alpha.f = 0.05),
      lwd = 3
    )
    points(
      draws_posterior[i, 1],
      draws_posterior[i, 2],
      pch = 21,
      col = NA,
      bg = adjustcolor(&quot;gray10&quot;, alpha.f = 0.25)
    )
  }
}</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6,"fig.height":6,"fig.retina":2,"fig.align":"center","fig.keep":"high","fig.show":"asis","out.width":576,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
</div>
</div>
<div id="section-convergence-diagnostics" class="section level2">
<h2>Convergence diagnostics</h2>
<div id="section-why-diagnose" class="section level3">
<h3>Why diagnose?</h3>
<p>MCMC algorithms use iterative algorithms to explore posterior
distributions and to produce numerical approximations thereof.</p>
<p>However, even with appropriately specified models and algorithms, we
can never know a priori if and when a chain has converged to its target
distribution. We must thus rely on <em>convergence diagnostics</em>.</p>
<p><em>Important:</em> Convergence diagnostics cannot show or prove
convergence. They can only show signs of non-convergence!</p>
<p>To conclude that the post-warmup draws of our sampler in fact explore
the target distribution, we want to show at least two things:</p>
<ol style="list-style-type: decimal">
<li>Every chain is in a stationary state (i.e., does not “wander off”
the target distribution)</li>
<li>Multiple independent chains are in the same stationary state (i.e.,
no convergence to different target distributions given identical
data)</li>
</ol>
</div>
<div id="section-generic-diagnostics" class="section level3">
<h3>Generic diagnostics</h3>
<p>Generic diagnostics (see <a
href="https://www.routledge.com/Bayesian-Methods-A-Social-and-Behavioral-Sciences-Approach-Third-Edition/Gill/p/book/9781439862483">Gill
2015, Ch. 14.3</a>) include:</p>
<ol style="list-style-type: decimal">
<li><strong>Potential scale reduction statistic</strong> <span
class="math inline">\(\hat{R}\)</span> (aka Gelman-Rubin convergence
diagnostic) <span class="math display">\[\small \widehat{Var}(\theta) =
(1 - \frac{1}{\mathtt{n_{iter}}})
\underbrace{\Bigg(\frac{1}{ \mathtt{n_{chains}} (\mathtt{n_{iter}} - 1)}
\sum_{j=1}^{\mathtt{n_{chains}}} \sum_{i=1}^{\mathtt{n_{iter}}}
(\theta_{ij} - \bar{\theta_j})^2 \Bigg)}_{\text{Within chain var}} +
\frac{1}{\mathtt{n_{iter}}}  \underbrace{\Bigg(\frac{\mathtt{n_{iter}}}{\mathtt{n_{chains}
- 1}} \sum_{j=1}^{\mathtt{n_{chains}}} (\bar{\theta_j} -
\bar{\bar{\theta}})^2\Bigg)}_{\text{Between chain var}}\]</span>
<ul>
<li>low values indicate that chains are stationary (convergence to
target distribution within chains)</li>
<li>low values indicate that chains mix (convergence to same target
distribution across chains)</li>
</ul></li>
<li><strong>Geweke Time-Series Diagnostic</strong>: Compare
non-overlapping post-warmup portions of each chain to test
within-convergence</li>
<li><strong>Heidelberger and Welch Diagnostic</strong>: Compare early
post-warmup portion of each chain with late portion to test
within-convergence</li>
<li><strong>Raftery and Lewis Integrated Diagnostic</strong>: Evaluates
the full chain of a pilot run (requires that
<code>save_warmup = TRUE</code>) to estimate minimum required length of
warmup and sampling</li>
</ol>
<p>These are implemented as part of the <code>coda</code> package
(Output Analysis and Diagnostics for MCMC).</p>
</div>
<div id="section-visual-diagnostics" class="section level3">
<h3>Visual diagnostics</h3>
<p>The most widespread visual diagnostics are:</p>
<ol style="list-style-type: decimal">
<li><strong>Traceplots</strong>: Visually inspect if chains are
stationary and have converged to the same distribution</li>
<li><strong>Autocorrelation plots</strong>: Visually inspect if the
chain is sluggish in exploring the parameter space.</li>
</ol>
</div>
<div id="section-application-1" class="section level3">
<h3>Application</h3>
<p>In the following, we will use multiple chain runs of our sampler in
conjunction with the <code>coda</code> package to check for signs of
non-convergence.</p>
<p>Note that <code>coda</code> functions require that we combine our
chains into <code>mcmc.list</code> objects.</p>
</div>
<div id="section-raftery-and-lewis-integrated-diagnostic"
class="section level3">
<h3>Raftery and Lewis Integrated Diagnostic</h3>
<p>The Raftery-Lewis diagnostic takes a single chain, including warm-up
draws, to estimate the minimum required length of warmup and sampling
runs:</p>
<div class="tutorial-exercise" data-label="raftery-lewis"
data-caption="Code" data-completion="1" data-diagnostics="1"
data-startover="1" data-lines="0">
<pre class="text"><code># Example: Gill 2015, p. 503
# If we want a 95% credible interval around the median 
# with reliability between 92.5% and 97.5%, we need:
q &lt;- 0.5    # quantile of interest
r &lt;- 0.0125 # margin of error
s &lt;- 0.95   # desired reliability

## The recommend length for the pilot run:
n &lt;- ceiling((qnorm(.5 * (s + 1)) * sqrt(q * (1 - q)) / r) ^ 2)

# Pilot run
draws_pilot &lt;-
  draw_from_posterior(
    theta = 0,
    omega = .1,
    alpha = 20,
    beta = 200,
    n_warmup = 0,
    n_draws = n,
    data = gles$sup_afd,
    keep_warmup = TRUE
  )

# Save as mcmc
draws_pilot &lt;- as.mcmc(simplify2array(draws_pilot))

# Diagnose
raftery.diag(
  draws_pilot,
  q = q,
  r = r,
  s = s
)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
</div>
<div id="section-gelman-rubin-geweke-and-heidelberger-welch-diagnostics"
class="section level3">
<h3>Gelman-Rubin, Geweke, and Heidelberger-Welch diagnostics</h3>
<p>We will use the recommended run-length from the Raftery-Lewis
diagnostic for four independent runs of our sampler.</p>
<p>We will ensure that ou chains run independently (i.e., using
different starting values and different random number sequences) by
setting different seed:</p>
<pre class="r"><code>seeds &lt;- sample(10001:99999, 4)
draws_multiple_chains &lt;- lapply(seeds,
                                function(seed) {
                                  as.mcmc(simplify2array(
                                    draw_from_posterior(
                                      theta = 0,
                                      omega = .1,
                                      alpha = 20,
                                      beta = 200,
                                      n_warmup = 200,
                                      n_draws = 6147,
                                      data = gles$sup_afd,
                                      keep_warmup = FALSE,
                                      seed = seed
                                    )
                                  ))
                                })

# Save as mcmc.list
draws_multiple_chains &lt;- as.mcmc.list(draws_multiple_chains)</code></pre>
<div class="tutorial-exercise" data-label="other-diagnostics"
data-caption="Code" data-completion="1" data-diagnostics="1"
data-startover="1" data-lines="0">
<pre class="text"><code># Diagnose
coda::gelman.diag(draws_multiple_chains, autoburnin = FALSE)
coda::geweke.diag(draws_multiple_chains, frac1 = .1, frac2 = .5)  
coda::heidel.diag(draws_multiple_chains, pvalue = .1)             </code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
</div>
<div id="section-trace-plots" class="section level3">
<h3>Trace plots</h3>
<div class="tutorial-exercise" data-label="trace" data-caption="Code"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0">
<pre class="text"><code>par(mfrow = c(1, 2))
coda::traceplot(draws_multiple_chains, smooth = TRUE)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
</div>
<div id="section-autocorrelation-plots" class="section level3">
<h3>Autocorrelation plots</h3>
<div class="tutorial-exercise" data-label="autocorr" data-caption="Code"
data-completion="1" data-diagnostics="1" data-startover="1"
data-lines="0">
<pre class="text"><code>coda::autocorr.plot(draws_multiple_chains)</code></pre>
<script type="application/json" data-opts-chunk="1">{"fig.width":6.5,"fig.height":4,"fig.retina":2,"fig.align":"default","fig.keep":"high","fig.show":"asis","out.width":624,"warning":true,"error":false,"message":true,"exercise.df_print":"paged","exercise.checker":"NULL"}</script>
</div>
</div>
</div>
<div id="section-contrasting-bayesian-and-frequentist-approaches"
class="section level2">
<h2>Contrasting Bayesian and frequentist approaches</h2>
<div id="section-priors" class="section level3">
<h3>Priors</h3>
<ul>
<li>Choice of priors allows us to explicitly incorporate prior beliefs
about parameters…</li>
<li>…but also comes with the obligation to be transparent and
responsible with respect to the subjectivity this brings into our
analyses</li>
</ul>
</div>
<div id="section-inference" class="section level3">
<h3>Inference</h3>
<div id="section-interpretation" class="section level4">
<h4>Interpretation</h4>
<ul>
<li>Bayesian inference does note presume large (quasi-infinite) streams
of independent identically distributed (IID) data; data are considered
fixed, parameters random.</li>
<li>This allows for straightforward interpretations of inferential
uncertainty:
<ul>
<li><em>Bayesian</em>: “Given the data, we can conclude that there is a
95% probability that the mean is between 8 and 12, with highest
probability density at a value of 10”.</li>
<li><em>Frequentist</em>: “If we took a large number of independent
random samples from the same population and constructed a 95% confidence
interval around the sample for each of them, these confidence intervals
would contain the <em>true</em> population mean 95% of the time. Given
this long-run frequency, we are 95% confident that the specific 95%
confidence intervals from our singular sample contains the true
population parameter…”.</li>
</ul></li>
</ul>
</div>
<div id="section-finite-sample-and-asymptotic-properties"
class="section level4">
<h4>Finite-sample and asymptotic properties</h4>
<ul>
<li>Bayesian inference allows for exact inference in finite-sample
applications where the asymptotic properties of MLE estimators are
implausible (normal approximation, etc.)…</li>
<li>…yet, posterior distribution often asymptotically converge to the
sampling distribution of MLE estimators (<a
href="https://en.wikipedia.org/wiki/Bernstein%E2%80%93von_Mises_theorem">Bernstein-von-Mises
Theorem</a>)</li>
</ul>
</div>
</div>
<div id="section-flexibility-and-computational-reliability"
class="section level3">
<h3>Flexibility and computational reliability</h3>
<ul>
<li>The use of MCMC algorithms for probabilistic approximate inference
makes Bayesian approaches incredibly flexible and allows for
computationally reliable estimation of complex, analytically intractable
marginal likelihoods (avoids integration of super high-dimensional
integrals)…</li>
<li>…but sometimes comes with the necessity of high computational
resources and/or long computation times, and always necessitates
convergence diagnosis and model checking</li>
</ul>
<p>
<script type="application/shiny-prerendered" data-context="server-start">
## --- learnr ---
if ("learnr" %in% (.packages()))
  detach(package:learnr, unload = TRUE)
library(learnr)
knitr::opts_chunk$set(echo = FALSE)

## ---- CRAN Packages ----
## Save package names as a vector of strings
pkgs <-  c("coda", "foreign")

## Install uninstalled packages
lapply(pkgs[!(pkgs %in% installed.packages())], 
       install.packages,
       repos='http://cran.us.r-project.org')

## Load all packages to library and adjust options
lapply(pkgs, library, character.only = TRUE)

## ---- GitHub Packages ----


## ---- Global learnr Objects ----
gles <- 
  read.dta("https://github.com/denis-cohen/statmodeling/raw/main/data/gles.dta")

draw_from_prior <-
  function(theta,
           omega,
           alpha,
           beta,
           n_draws,
           seed = 20210329) {
    # Set seed
    set.seed(seed)
    
    # Take draws
    mu <- rnorm(n_draws, theta, 1 / sqrt(omega))
    tau <- rgamma(n_draws, alpha, beta)
    
    ## Return output
    return(list(mu = mu,
                tau = tau))
  }

draw_from_posterior <- function(theta,
                                omega,
                                alpha,
                                beta,
                                n_warmup,
                                n_draws,
                                data,
                                seed = 20210329,
                                keep_warmup = TRUE) {
  # Set seed
  set.seed(seed)

  # Length of chain
  len_chain <- n_warmup + n_draws
  
  # Data characteristics
  n_data <- length(data)  
  mean_data <- mean(data) 

  # Initialize containers
  mu <- rep(NA, len_chain)
  tau <- rep(NA, len_chain)
  
  # Run Gibbs sampler
  for (i in seq_len(len_chain)) {
    if (i == 1) {
      ## Iteration 1: Initialize from prior
      alpha_star <- alpha
      beta_star <- beta
    } else {
      ## Iterations 2+: Update alpha and beta
      alpha_star <- alpha + n_data / 2
      beta_star <- beta + sum(((data - mu[i - 1]) ^ 2) / 2)
    }
    
    ## Sample tau
    tau[i] <- rgamma(1, alpha_star, beta_star)
    
    ## Update theta and omega
    theta_star <-
      (omega * theta + n_data * tau[i] * mean_data) /
      (omega + n_data * tau[i])
    omega_star <- omega + n_data * tau[i]
    
    ## Sample mu
    mu[i] <- rnorm(1, theta_star, 1 / sqrt(omega_star))
  }
  
  ## Conditionally discard warmup-draws
  if (!keep_warmup) {
    tau <- tau[(n_warmup + 1):len_chain]
    mu <- mu[(n_warmup + 1):len_chain]
  }
  
  ## Return output
  return(list(mu = mu,
              tau = tau))
}

seeds <- sample(10001:99999, 4)
draws_multiple_chains <- lapply(seeds,
                                function(seed) {
                                  as.mcmc(simplify2array(
                                    draw_from_posterior(
                                      theta = 0,
                                      omega = .1,
                                      alpha = 20,
                                      beta = 200,
                                      n_warmup = 200,
                                      n_draws = 6147,
                                      data = gles$sup_afd,
                                      keep_warmup = FALSE,
                                      seed = seed
                                    )
                                  ))
                                })

# Save as mcmc.list
draws_multiple_chains <- as.mcmc.list(draws_multiple_chains)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::register_http_handlers(session, metadata = NULL)
</script>


<script type="application/shiny-prerendered" data-context="server">
session$onSessionEnded(function() {
        learnr:::session_stop_event(session)
      })
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-prior-sim-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-prior-sim-code-editor`)), session)
output$`tutorial-exercise-prior-sim-output` <- renderUI({
  `tutorial-exercise-prior-sim-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-posterior-sim-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-posterior-sim-code-editor`)), session)
output$`tutorial-exercise-posterior-sim-output` <- renderUI({
  `tutorial-exercise-posterior-sim-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-joint-posterior-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-joint-posterior-code-editor`)), session)
output$`tutorial-exercise-joint-posterior-output` <- renderUI({
  `tutorial-exercise-joint-posterior-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-raftery-lewis-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-raftery-lewis-code-editor`)), session)
output$`tutorial-exercise-raftery-lewis-output` <- renderUI({
  `tutorial-exercise-raftery-lewis-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-other-diagnostics-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-other-diagnostics-code-editor`)), session)
output$`tutorial-exercise-other-diagnostics-output` <- renderUI({
  `tutorial-exercise-other-diagnostics-result`()
})
</script>


<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-trace-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-trace-code-editor`)), session)
output$`tutorial-exercise-trace-output` <- renderUI({
  `tutorial-exercise-trace-result`()
})
</script>
 
<script type="application/shiny-prerendered" data-context="server">
`tutorial-exercise-autocorr-result` <- learnr:::setup_exercise_handler(reactive(req(input$`tutorial-exercise-autocorr-code-editor`)), session)
output$`tutorial-exercise-autocorr-output` <- renderUI({
  `tutorial-exercise-autocorr-result`()
})
</script>
</p>
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["header-attrs"]},{"type":"character","attributes":{},"value":["2.16"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pandoc"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["header-attrs.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"character","attributes":{},"value":["<style>h1 {font-size: 34px;}\n       h1.title {font-size: 38px;}\n       h2 {font-size: 30px;}\n       h3 {font-size: 24px;}\n       h4 {font-size: 18px;}\n       h5 {font-size: 16px;}\n       h6 {font-size: 12px;}\n       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}\n       pre:not([class]) { background-color: white }<\/style>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["navigation"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/navigation-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tabsets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["default.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["font-awesome"]},{"type":"character","attributes":{},"value":["5.1.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/fontawesome"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["css/all.css","css/v4-shims.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.16"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["4.4.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["idb-keyvalue"]},{"type":"character","attributes":{},"value":["3.2.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/idb-keyval"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["idb-keyval-iife-compat.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-autocompletion"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-autocompletion.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-diagnostics"]},{"type":"character","attributes":{},"value":["0.10.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-diagnostics.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["ace"]},{"type":"character","attributes":{},"value":["1.2.6"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/ace"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["ace.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["clipboardjs"]},{"type":"character","attributes":{},"value":["1.5.15"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/clipboardjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["clipboard.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.10.1"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48]}},"value":[{"type":"character","attributes":{},"value":["base","bslib","cachem","cli","coda","compiler","datasets","digest","ellipsis","evaluate","fastmap","foreign","graphics","grDevices","grid","highr","htmltools","htmlwidgets","httpuv","jquerylib","jsonlite","knitr","later","lattice","learnr","lifecycle","magrittr","markdown","methods","mime","promises","R6","Rcpp","rlang","rmarkdown","rprojroot","rstudioapi","sass","shiny","stats","stringi","stringr","tools","utils","withr","xfun","xtable","yaml"]},{"type":"character","attributes":{},"value":["4.2.1","0.4.0","1.0.6","3.4.0","0.19-4","4.2.1","4.2.1","0.6.29","0.3.2","0.16","1.1.0","0.8-82","4.2.1","4.2.1","4.2.1","0.9","0.5.3","1.5.4","1.6.6","0.1.4","1.8.0","1.40","1.3.0","0.20-45","0.10.1","1.0.2","2.0.3","1.1","4.2.1","0.12","1.2.0.1","2.5.1","1.0.9","1.0.5","2.16","2.0.3","0.14","0.4.2","1.7.2","4.2.1","1.7.8","1.4.1","4.2.1","4.2.1","2.5.0","0.33","1.8-4","2.3.5"]}]}]}
</script>
<!--/html_preserve-->
</div>
</div>

</div> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h2 class="title toc-ignore" style="display:none;">Lecture: Bayesian
Fundamentals</h2>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</div> <!-- bandContent page -->
</div> <!-- pageContent band -->




<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>

</html>
