<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">

<head>

<meta charset="utf-8">
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />



<meta name="progressive" content="true" />
<meta name="allow-skip" content="true" />
<meta name="learnr-version-prerender" content="0.11.1" />

<title>Lecture: Generalized Linear Models</title>

<!-- header-includes START -->
<!-- HEAD_CONTENT -->
<!-- header-includes END -->
<!-- HEAD_CONTENT -->

<!-- highlightjs -->
<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>


<!-- taken from https://github.com/rstudio/rmarkdown/blob/de8a9c38618903627ca509f5401d50a0876079f7/inst/rmd/h/default.html#L293-L343 -->
<!-- tabsets -->
<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>
<!-- end tabsets -->

<link rel="stylesheet" href="css/learnr-theme.css" type="text/css" />

</head>

<body>
<a class='sr-only sr-only-focusable visually-hidden-focusable' href='#learnr-tutorial-content'>Skip to Tutorial Content</a>



<div class="pageContent band">
<main class="bandContent page">

<article class="topics" id="learnr-tutorial-content">

<div id="section-generalized-linear-models" class="section level2">
<h2>Generalized linear models</h2>
<div id="section-goals-for-this-session" class="section level3">
<h3>Goals for this session</h3>
<ul>
<li>To understand generalized linear models (GLM) as a unified
methodology for producing parameter estimates (<a
href="https://www.researchgate.net/publication/235726158_Generalized_Linear_Models_A_Unified_Approach">Gill
2001</a>, <a
href="https://us.sagepub.com/en-us/nam/generalized-linear-models/book257965">Gill
and Torres 2019</a>).</li>
<li>To understand that all GLM produce two important, intuitive, and
substantively meaningful quantities of interest that can be derived from
the parameter estimates and the data (<a
href="https://gking.harvard.edu/files/gking/files/making.pdf">King et
al. 2000</a>):
<ol style="list-style-type: decimal">
<li>Expected values (conditional expectations)</li>
<li>Average marginal effects or first differences</li>
</ol></li>
<li>To learn how to estimate these quantities and how to specify the
uncertainty about our inferences using simulation techniques (<a
href="https://gking.harvard.edu/files/gking/files/making.pdf">King et
al. 2000</a>).</li>
</ul>
</div>
<div id="section-the-three-parts-of-every-glm" class="section level3">
<h3>The three parts of every GLM</h3>
<p>All generalized linear models have three characteristic parts:</p>
<div id="section-family" class="section level4">
<h4>Family</h4>
<ul>
<li>The family stipulates a stochastic process that can plausibly
generate an outcome <span class="math inline">\(y\)</span></li>
<li>This means we choose a pdf or pmf for <span
class="math inline">\(y\)</span> given some parameters: <span
class="math inline">\(y_i \sim \text{f}(\theta_i, \psi)\)</span></li>
<li>The choice usually depends on the distributional properties of <span
class="math inline">\(y\)</span></li>
<li>Aliases: data-generating process, generative model, likelihood
function</li>
</ul>
</div>
<div id="section-linear-component" class="section level4">
<h4>Linear component</h4>
<ul>
<li>A linear model <span class="math inline">\(y_i^{\ast} =
\mathbf{x}_i^{\prime} \beta + \epsilon_i\)</span></li>
<li>The goal of inference is the estimation of <span
class="math inline">\(\beta\)</span></li>
<li>From, this, we can derive our <em>systematic component</em> or
<em>linear predictor</em>, <span class="math inline">\(\eta_i =
\mathbf{x}_i^{\prime} \beta\)</span></li>
</ul>
</div>
<div id="section-inverse-link-function" class="section level4">
<h4>Inverse link function</h4>
<ul>
<li>A function that transforms the systematic component <span
class="math inline">\(\eta_i\)</span> such that it represents a
characteristic <em>parameter</em> <span
class="math inline">\(\theta_i\)</span> of the family</li>
<li><span class="math inline">\(\theta_i = g^{-1}(\eta_i)\)</span></li>
</ul>
</div>
</div>
<div id="section-in-a-nutshell" class="section level3">
<h3>In a nutshell</h3>
<p>Putting it all together, a GLM is given by</p>
<p><span class="math display">\[y_i \sim \text{f}(\theta_i =
g^{-1}(\mathbf{x}_i^{\prime} \beta), \psi)\]</span></p>
<p>where <span class="math inline">\(\psi\)</span> is an auxiliary
parameter that will sometimes be estimated (e.g., <span
class="math inline">\(\sigma^2\)</span> in the linear model) and
sometimes be fixed.</p>
<p>Every generalized linear model is a <em>special case</em> of this
general framework.</p>
</div>
<div id="section-example-1-the-linear-model" class="section level3">
<h3>Example 1: The linear model</h3>
<ul>
<li>While every GLM is a special case, the linear model is arguably a
<em>very</em> special case.</li>
<li>Why? Because its link function is the <em>identity
function</em>.</li>
<li>This not only makes the notation easier, but also means that the
<span class="math inline">\(\beta\)</span>’s are <em>directly
interpretable</em> on the scale of the outcome.</li>
</ul>
<div id="section-the-three-parts" class="section level4">
<h4>The three parts:</h4>
<ul>
<li>Family: <span class="math display">\[y_i \sim \text{N}(\eta_i,
\sigma^2)\]</span></li>
<li>Linear component: <span class="math display">\[y_i =
\underbrace{\mathbf{x}_i^{\prime} \beta}_{\eta_i} +
\underbrace{\epsilon_i}_{\sim \text{N}(0, \sigma^2)}\]</span></li>
<li>Inverse link function: <span class="math display">\[\eta_i =
\text{id}(\eta_i)\]</span></li>
</ul>
<p>Thus, the linear model is given by</p>
<p><span class="math display">\[y_i \sim \text{N}(\mathbf{x}_i^{\prime}
\beta, \sigma^2)\]</span> where both <span
class="math inline">\(\beta\)</span> and <span
class="math inline">\(\sigma^2\)</span> are being estimated.</p>
</div>
</div>
<div id="section-example-2-the-probit-model" class="section level3">
<h3>Example 2: The probit model</h3>
<p>The probit model is a popular choice for modeling idiosyncratic
binary choices.</p>
<div id="section-the-three-parts-1" class="section level4">
<h4>The three parts:</h4>
<ul>
<li>Family: <span class="math display">\[y_i \sim
\text{Bernoulli}(\pi_i)\]</span></li>
<li>Linear component: <span class="math display">\[y_i^{\ast} =
\underbrace{\mathbf{x}_i^{\prime} \beta}_{\eta_i} +
\underbrace{\epsilon_i}_{\sim \text{N}(0, 1)}\]</span></li>
<li>Inverse link function: <span class="math display">\[\pi_i =
\Phi(\eta_i)\]</span></li>
</ul>
<p>Thus, the probit model is given by</p>
<p><span class="math display">\[y_i \sim
\text{Bernoulli}(\Phi(\mathbf{x}_i^{\prime} \beta))\]</span></p>
<p>where the <span class="math inline">\(\beta\)</span> vector is being
estimated. <span class="math inline">\(\Phi\)</span> is the standard
normal CDF. Note that the standard normal CDF follows from fixing the
variance of the error term, <span class="math inline">\(\epsilon \sim
\text{N}(0, 1)\)</span>.</p>
</div>
</div>
<div id="section-example-3-the-logit-model" class="section level3">
<h3>Example 3: The logit model</h3>
<p>With a slight change in the error distribution in the linear
component and a corresponding change in the inverse link function, we
can derive the logit model for binary choices.</p>
<div id="section-the-three-parts-2" class="section level4">
<h4>The three parts:</h4>
<ul>
<li>Family: <span class="math display">\[y_i \sim
\text{Bernoulli}(\pi_i)\]</span></li>
<li>Linear component: <span class="math display">\[y_i^{\ast} =
\underbrace{\mathbf{x}_i^{\prime} \beta}_{\eta_i} +
\underbrace{\epsilon_i}_{\sim \text{Logistic}(0, 1)}\]</span></li>
<li>Inverse link function: <span class="math display">\[\pi_i =
\frac{\exp(\eta_i)}{1 + \exp(\eta_i)}\]</span></li>
</ul>
<p>Thus, the logit model is given by</p>
<p><span class="math display">\[y_i \sim
\text{Bernoulli}\left(\frac{\exp(\eta_i)}{1 +
\exp(\eta_i)}\right)\]</span></p>
<p>where the <span class="math inline">\(\beta\)</span> vector is being
estimated. <span class="math inline">\(\frac{\exp(\cdot)}{1 +
\exp(\cdot)}\)</span> is the standard logistic CDF. Shorthand: <span
class="math inline">\(\text{logit}^{-1}(\cdot)\)</span>.</p>
<p>As you can see, the <em>assumed</em> distribution of the error term
on the latent variable <span class="math inline">\(y_i^{\ast}\)</span>
dictates our choice of the inverse link function.</p>
<p>As the error distribution is fixed and its parameters are not being
estimated, it is not in itself of substantive interest.</p>
</div>
</div>
</div>
<div id="section-glm-typology" class="section level2">
<h2>GLM Typology</h2>
<div id="section-single-family-models" class="section level3">
<h3>Single-family models</h3>
<p>We will first focus on models whose likelihood function follows a
single pdf or pmf.</p>
</div>
<div id="section-univariate-eta_i-univariate-theta_i"
class="section level3">
<h3>Univariate <span class="math inline">\(\eta_i\)</span>, univariate
<span class="math inline">\(\theta_i\)</span></h3>
<p>Among the simplest GLM are those models that require</p>
<ul>
<li>a single family</li>
<li>a univariate systematic component <span
class="math inline">\(\eta_i\)</span></li>
<li>a univariate parameter <span
class="math inline">\(\theta_i\)</span></li>
</ul>
<p>Examples include the three models discussed above:</p>
<ul>
<li>The linear model (<span class="math inline">\(\eta_i = \theta_i =
\mu_i\)</span>)</li>
<li>The probit model (<span class="math inline">\(\eta_i =
\mathbf{x}_i^{\prime}\beta\)</span>, <span
class="math inline">\(\theta_i = \Phi(\eta_i)\)</span>)</li>
<li>The logit model (<span class="math inline">\(\eta_i =
\mathbf{x}_i^{\prime}\beta\)</span>, <span
class="math inline">\(\theta_i =
\text{logit}^{-1}(\eta_i)\)</span>)</li>
</ul>
<p>An additional example would be the <em>Poisson model</em> for
counts:</p>
<ul>
<li><span class="math inline">\(y_i \sim \text{Poisson}(\exp(\theta_i =
\mathbf{x}_i^{\prime}\beta))\)</span></li>
</ul>
</div>
<div id="section-univariate-eta_i-multivariate-theta_i"
class="section level3">
<h3>Univariate <span class="math inline">\(\eta_i\)</span>, multivariate
<span class="math inline">\(\theta_i\)</span></h3>
<p>Things get a bit more intricate when we model multivariate outcomes,
e.g., discrete choice across multiple categories.</p>
<p>Multi-categorical discrete choice outcomes typically require that we
stipulate a <em>categorical distribution</em> which requires
choice-specific probability parameters <span
class="math inline">\(\theta_{ij} = \Pr(Y_i = j)\)</span>.</p>
<p>Thus, <span class="math inline">\(\mathbf{\theta}_i\)</span> is a
length-<span class="math inline">\(J\)</span> vector for each <span
class="math inline">\(i=1,..,N\)</span>: <span
class="math inline">\(\mathbf{\theta}_i = \begin{bmatrix} \theta_{i1}
&amp; \dots &amp; \theta_{iJ}\end{bmatrix}^{\prime}\)</span>, where
<span class="math inline">\(\sum_{j=1}^{J} \theta_{ij} = 1\)</span> for
each <span class="math inline">\(i=1,..,N\)</span>.</p>
<p>A model that accommodates this while using a single univariate linear
predictor <span class="math inline">\(\eta_i\)</span> is the <em>ordered
logit model</em>, which can be used for modeling ordered outcomes with
<span class="math inline">\(J\)</span> categories.</p>
<div id="section-family-1" class="section level4">
<h4>Family</h4>
<p><span class="math display">\[y_{ij} \sim
\text{Categorical}(\theta_{ij})\]</span></p>
</div>
<div id="section-systematic-component" class="section level4">
<h4>Systematic component</h4>
<p>The linear predictor is <span class="math inline">\(\eta_i =
\mathbf{x}_i^{\prime}\beta\)</span>, where <span
class="math inline">\(\beta\)</span> does <em>not</em> include an
intercept and <span class="math inline">\(\mathbf{x}_i^{\prime}\)</span>
does not include a leading one.</p>
<p>In place of an intercept, the model produces <span
class="math inline">\(J-1\)</span> ordered threshold parameters <span
class="math inline">\(\kappa\)</span>.</p>
</div>
<div id="section-link-function" class="section level4">
<h4>Link function</h4>
<p>We then use the inverse logit link function to retrieve <span
class="math inline">\(J\)</span> probabilities <span
class="math inline">\(\theta_{ij}\)</span> that <span
class="math inline">\(\eta_i\)</span> exceeds a given threshold <span
class="math inline">\(\kappa\)</span>:</p>
<p><span class="math display">\[\begin{split}\Pr(y_i = j | \mathbf{x}_i)
&amp; =\Pr(\kappa_{j-1} &lt; \eta_i \leq \kappa_j) \\ &amp;
=\text{logit}^{-1} (\kappa_j - \eta_i) - \text{logit}^{-1} (\kappa_{j-1}
- \eta_i)\end{split}\]</span></p>
</div>
</div>
<div id="section-multivariate-eta_i-multivariate-theta_i"
class="section level3">
<h3>Multivariate <span class="math inline">\(\eta_i\)</span>,
multivariate <span class="math inline">\(\theta_i\)</span></h3>
<p>When moving from ordered to unordered discrete choices, we not only
need to model choice-specific probability parameters <span
class="math inline">\(\theta_{ij}\)</span> but also choice-specific
linear predictors <span class="math inline">\(\eta_{ij}\)</span>.</p>
<p>An example is the <em>multinomial logistic regression model</em>.</p>
<div id="section-family-2" class="section level4">
<h4>Family</h4>
<p><span class="math display">\[y_{ij} \sim
\text{Categorical}(\theta_{ij})\]</span></p>
</div>
<div id="section-systematic-component-1" class="section level4">
<h4>Systematic component</h4>
<p>The linear predictor is <span class="math inline">\(\eta_{ij} =
\mathbf{x}_i^{\prime}\beta_j + \mathbf{z}_{ij}^{\prime} \gamma\)</span>.
For statistical identification, we must set the <span
class="math inline">\(\beta\)</span> vector for one category to zero,
e.g., <span class="math inline">\(\beta_J = \mathbf{0}\)</span>.</p>
</div>
<div id="section-link-function-1" class="section level4">
<h4>Link function</h4>
<p>The link function is the <em>softmax</em> function, a multivariate
generalization of the inverse logit function:</p>
<p><span class="math display">\[\Pr(y_i = j) = \text{softmax}(\eta_{ij})
= \frac{\exp (\eta_{ij})}{\sum_{j=1}^{J} \exp(\eta_{ij})}\]</span></p>
</div>
</div>
<div id="section-multiple-families" class="section level3">
<h3>Multiple families</h3>
<p>Some models stipulate complex data generating processes. They combine
multiple families <span class="math inline">\(f\)</span> in the
likelihood (which means that the likelihood will be a mixture of the
constitutive likelihoods).</p>
</div>
<div id="section-univariate-eta_i-multivariate-theta_i-1"
class="section level3">
<h3>Univariate <span class="math inline">\(\eta_i\)</span>, multivariate
<span class="math inline">\(\theta_i\)</span></h3>
<p>These models estimate only one set of parameters <span
class="math inline">\(\beta\)</span>, but use different link functions
for translating the resulting linear predictor <span
class="math inline">\(\eta_i\)</span> into different parameters <span
class="math inline">\(\theta_i^{f}\)</span> that match the stipulated
data-generating processes <span class="math inline">\(f\)</span>.</p>
<p>A well-known case is the <em>tobit model</em> for censored data. For
instance, a left-censored tobit model with a lower bound at <span
class="math inline">\(y_L = 0\)</span> jointly accommodates a Bernoulli
data-generating process for <span class="math inline">\(\Pr(y &gt;
y_L)\)</span> and a normal data-generating process for the variation in
<span class="math inline">\(y\)</span> given <span
class="math inline">\(y &gt; y_L\)</span>. By assumption, both
data-generating processes are governed by the same parameters <span
class="math inline">\(\beta\)</span>.</p>
<p>Similar logics apply to other models that involve censored data,
e.g., in survival analysis.</p>
</div>
<div id="section-multivariate-eta_i-multivariate-theta_i-1"
class="section level3">
<h3>Multivariate <span class="math inline">\(\eta_i\)</span>,
multivariate <span class="math inline">\(\theta_i\)</span></h3>
<div id="section-two-part-models" class="section level4">
<h4>Two-part models</h4>
<p>A generalization of this are <em>two-part models</em>. Instead of
estimating one set of parameters <span
class="math inline">\(\beta\)</span> and using different link functions
for translating <span class="math inline">\(\eta_i\)</span> into <span
class="math inline">\(\theta_i^{f}\)</span>, these models estimate
distinct sets of parameters <span
class="math inline">\(\beta^{f}\)</span> for each of the stipulated
data-generating processes.</p>
<p>An example is a <em>hurdle model</em>. Unlike a left-censored tobit
model, this model allows for the possibility that different sets of
parameters govern the data-generating process for <span
class="math inline">\(\Pr(y &gt; y_L)\)</span> and the normal
data-generating process for the variation in <span
class="math inline">\(y\)</span> given <span class="math inline">\(y
&gt; y_L\)</span>.</p>
</div>
</div>
<div id="section-finite-mixtures-of-identical-families"
class="section level3">
<h3>Finite mixtures of identical families</h3>
<p>A different intuition underlies finite mixture models. Rather than
stipulating different <em>families</em> depending on the observed values
of each unit, finite mixture models stipulate that substantively
different data generating processes of the <em>same family</em> may
generate the observed outcomes of all observations.</p>
</div>
</div>
<div id="section-quantities-of-interest" class="section level2">
<h2>Quantities of interest</h2>
<div id="section-expected-values" class="section level3">
<h3>Expected values</h3>
<ul>
<li>The <em>expected value</em> tells you where to expect the
<em>conditional mean</em> of <span class="math inline">\(y\)</span>
given some covariate values <span
class="math inline">\(\mathbf{x}\)</span> on the scale of <span
class="math inline">\(y\)</span>.</li>
<li>For most (but not all) GLM, the expected value is directly given by
our estimate of the parameter <span class="math inline">\(\theta_i =
g^{-1}(\mathbf{x}_i^{\prime} \beta)\)</span>:
<ul>
<li>Linear model: <span class="math inline">\(\mathbb{E}[y|\mathbf{x}] =
\mathbf{x}_i^{\prime} \beta\)</span> (“predicted value”)</li>
<li>Probit model: <span class="math inline">\(\mathbb{E}[y|\mathbf{x}] =
\Phi(\mathbf{x}_i^{\prime} \beta)\)</span> (“predicted
probability”)</li>
<li>Logit model: <span class="math inline">\(\mathbb{E}[y|\mathbf{x}] =
\text{logit}^{-1}(\mathbf{x}_i^{\prime} \beta)\)</span> (“predicted
probability”)</li>
</ul></li>
</ul>
</div>
<div id="section-first-differences" class="section level3">
<h3>First differences</h3>
<ul>
<li>A first difference is the difference between two expected
values.</li>
<li>It usually gives an estimate of how changing one covariate <span
class="math inline">\(d\)</span> affects our conditional expectation of
<span class="math inline">\(y\)</span> while holding all else (<span
class="math inline">\(\mathbf{x}\)</span>) constant.
<ul>
<li>Linear model: <span class="math inline">\(\mathbb{E}[y|d_1,
\mathbf{x}] - \mathbb{E}[y| d_0,\mathbf{x}] = (\alpha + \tau d_1 +
\mathbf{x}_i^{\prime} \beta) - (\alpha + \tau d_0 +
\mathbf{x}_i^{\prime} \beta) = \tau (d_1 - d_0)\)</span></li>
<li>Probit model: <span class="math inline">\(\mathbb{E}[y|d_1,
\mathbf{x}] - \mathbb{E}[y| d_0,\mathbf{x}] = \Phi(\alpha + \tau d_1 +
\mathbf{x}_i^{\prime} \beta)- \Phi(\alpha + \tau d_0 +
\mathbf{x}_i^{\prime} \beta)\)</span></li>
<li>Logit model: <span class="math inline">\(\mathbb{E}[y|d_1,
\mathbf{x}] - \mathbb{E}[y| d_0,\mathbf{x}] = \text{logit}^{-1}(\alpha +
\tau d_1 + \mathbf{x}_i^{\prime} \beta)- \text{logit}^{-1}(\alpha + \tau
d_0 + \mathbf{x}_i^{\prime} \beta)\)</span></li>
</ul></li>
</ul>
<p>An important insight is that the first difference in the linear model
does <em>not</em> depend on the values of other covariates <span
class="math inline">\(\mathbf{x}\)</span>.</p>
<p>In all other GLM, the presence of an inverse link function makes
first differences sensitive to the choice of covariates <span
class="math inline">\(\mathbf{x}\)</span>!</p>
</div>
<div id="section-marginal-effects" class="section level3">
<h3>Marginal effects</h3>
<p>The marginal effect of a variable <span
class="math inline">\(d\)</span> on the expected value <span
class="math inline">\(\mathbb{E}[y|d, \mathbf{x}]\)</span> is given by
the marginal rate of change in <span
class="math inline">\(\mathbb{E}[y|d, \mathbf{x}]\)</span> for an
infinitesimal change in <span class="math inline">\(d\)</span>:</p>
<p><span class="math display">\[\frac{\mathbb{E}[y|d + \Delta_d,
\mathbf{x}] - \mathbb{E}[y|d, \mathbf{x}]}{\Delta_d}\]</span></p>
<p>As <span class="math inline">\(\Delta_d \rightarrow 0\)</span>, this
becomes <span class="math inline">\(\frac{\partial \mathbb{E}[y|d,
\mathbf{x}]}{\partial d}\)</span>.</p>
<p>For the linear model, this is mathematically straightforward:</p>
<p><span class="math display">\[\frac{\partial (\alpha + \tau d +
\mathbf{x}_i^{\prime} \beta)}{\partial d} = \tau\]</span></p>
<p>For all other GLM, we rely on <em>normalized first differences</em>
for a freely chosen shift <span
class="math inline">\(\Delta_d\)</span>.</p>
<p>For instance, the marginal effect in a probit model for a
<em>standard deviation increase</em> in <span
class="math inline">\(d\)</span> is given by</p>
<p><span class="math display">\[\frac{\mathbb{E}[y|d + \text{sd}(d),
\mathbf{x}] - \mathbb{E}[y|d, \mathbf{x}]}{\text{sd}(d)} =
\frac{\Phi(\alpha + \tau (d + \text{sd}(d)) + \mathbf{x}_i^{\prime}
\beta) - \Phi(\alpha + \tau d + \mathbf{x}_i^{\prime}
\beta)}{\text{sd}(d)}\]</span> As with first differences, the marginal
effect is thus sensitive to the choice of covariates <span
class="math inline">\(\mathbf{x}\)</span>!</p>
</div>
<div id="section-average-quantities-of-interest" class="section level3">
<h3>Average quantities of interest</h3>
<p>The sensitivity of first differences and marginal effects to the
choice of <span class="math inline">\(\mathbf{x}\)</span> is problematic
because makes these quantities of interest dependent on subjective
judgment.</p>
<p>For instance, the estimates of these quantities may differ
dramatically depending on whether we set all variables in <span
class="math inline">\(\mathbf{x}\)</span> to their sample means, sample
minimums, or sample maximums.</p>
<p>A remedy is the <em>observed values approach</em> (<a
href="https://onlinelibrary.wiley.com/doi/full/10.1111/j.1540-5907.2012.00602.x">Hanmer
and Kalkan 2013</a>), which involves two steps:</p>
<ol style="list-style-type: decimal">
<li>Calculate unit-specific quantities of interest at the observed
values <span class="math inline">\(\mathbf{x}_i\)</span> for each
observation <span class="math inline">\(i = 1,...,N\)</span></li>
<li>Average across the <span class="math inline">\(N\)</span>
unit-specific quantities to obtain the <em>average</em> quantities of
interest</li>
</ol>
<p>So for instance, the average first difference for a binary variable
<span class="math inline">\(d\)</span> in a probit model is given by</p>
<p><span class="math display">\[\frac{1}{N} \sum_{i=1}^{N}\Phi(\alpha +
\tau \times 1 + \mathbf{x}_i^{\prime} \beta) - \Phi(\alpha + \tau \times
0 + \mathbf{x}_i^{\prime} \beta)\]</span></p>
<p>Analogously, the average marginal effect for a one unit increase in a
continuous variable <span class="math inline">\(d\)</span> is given
by</p>
<p><span class="math display">\[\frac{1}{N} \sum_{i=1}^{N}\Phi(\alpha +
\tau (d_i + 1) + \mathbf{x}_i^{\prime} \beta) - \Phi(\alpha + \tau d_i +
\mathbf{x}_i^{\prime} \beta)\]</span></p>
</div>
<div id="section-quantities-of-interest-why" class="section level3">
<h3>Quantities of interest: why?</h3>
<p>The answers are simple:</p>
<ul>
<li>Your readers have a right to know!</li>
<li>It makes your research accessible to non-technical audiences.</li>
<li>Chances are: You will not truly understand your own findings without
it.</li>
</ul>
<div id="section-do-not" class="section level4">
<h4>Do not:</h4>
<blockquote>
“The logit-coefficient of our information treatment on turnout is <span
class="math inline">\(b = 1.5\)</span> (<span class="math inline">\(p
&lt; .05\)</span>). We thus conclude that there is a considerable
treatment effect.”
</blockquote>
</div>
<div id="section-do" class="section level4">
<h4>Do:</h4>
<blockquote>
“Our logit model yields a predicted turnout probability of <span
class="math inline">\(0.88\)</span> <span class="math inline">\([0.85,
0.91]\)</span> in the treatment group, compared to <span
class="math inline">\(0.63\)</span> <span class="math inline">\([0.59,
0.67]\)</span> in the control group. The corresponding difference of
<span class="math inline">\(0.25\)</span> <span
class="math inline">\([0.22, 0.28]\)</span> is of considerable
substantive magnitude and statistically significant at the 95% level.”
</blockquote>
</div>
</div>
</div>
<div id="section-the-simulation-approach" class="section level2">
<h2>The simulation approach</h2>
<div id="section-inferential-uncertainty-vs-fundamental-uncertainty"
class="section level3">
<h3>Inferential uncertainty vs fundamental uncertainty</h3>
<p><a href="https://gking.harvard.edu/files/gking/files/making.pdf">King
et al. (2000)</a> distinguish <em>inferential uncertainty</em> and
<em>fundamental uncertainty</em>.</p>
<ul>
<li><em>Inferential uncertainty</em> describes the problem that we never
know our parameters exactly.
<ul>
<li>Instead, we estimate them with some uncertainty that is represented
in their respective <em>sampling distribution</em>.</li>
<li>Example: In large samples, we assume that the mean of age in Germany
has a normal sampling distribution such that <span
class="math inline">\(\hat \mu \sim \text{N}(\bar x, \sigma_{\bar
x}^2)\)</span>, where <span class="math inline">\(\sigma_{\bar
x}\)</span> is the standard error of the mean.</li>
<li>Inferential uncertainty thus describes our uncertainty about
<em>estimates</em> via <em>sampling distributions</em>.</li>
</ul></li>
<li><em>Fundamental uncertainty</em> describes the randomness that comes
from the fact that we stipulate stochastic data-generating processes.
<ul>
<li>Example: Over and beyond our uncertainty regarding the true mean of
age in Germany, we have a stochastic model in mind that generates age,
e.g.: <span class="math inline">\(y \sim \text{N}(\hat \mu,
\hat\sigma^2)\)</span>. So we could generate a predictive distribution
of age from a normal distribution whose mean is the sample mean and
whose variance is the sample variance.</li>
<li>Fundamental uncertainty thus describes our uncertainty about
<em>predictions</em> via <em>predictive distributions</em>.</li>
</ul></li>
</ul>
</div>
<div id="section-the-glm-context" class="section level3">
<h3>The GLM context</h3>
<p>For a generic GLM, this means:</p>
<p><span class="math display">\[\underbrace{\underbrace{y_i \sim
\text{f}}_{\text{fund.}}(\theta_i = g^{-1}(\mathbf{x}_i^{\prime}
\underbrace{\beta), \psi}_{\text{inf.}})}_{\text{Total
uncertainty}}\]</span></p>
<ol style="list-style-type: decimal">
<li>Inferential uncertainty about the model parameters can be simulated
by taking draws from their joint sampling distribution.</li>
<li>Fundamental uncertainty can be simulated by taking draws of <span
class="math inline">\(\mathbf{y}\)</span> from <span
class="math inline">\(\mathbf{y} \sim f(\theta, \psi)\)</span>.</li>
<li>Total uncertainty can be simulated by simulating (1) within (2)</li>
</ol>
</div>
<div id="section-inferential-uncertainty-in-glm" class="section level3">
<h3>Inferential uncertainty in GLM</h3>
<p>Quantities of interest such as expected values, (average) marginal
effects, or (average) first differences are estimates of population
parameters.</p>
<p>Unless we engage in predictive modeling, we thus care primarily about
inferential uncertainty.</p>
<p>However:</p>
<ul>
<li>In GLM, we rarely estimate our quantities of interest directly.</li>
<li>We usually estimate our <em>model coefficients</em> <span
class="math inline">\(\beta\)</span>, from which we derive our
quantities of interest.</li>
<li>We thus only have information on the sampling distribution of <span
class="math inline">\(\beta\)</span>, <span class="math inline">\(\beta
\sim \text{MVN}(\hat\beta, \hat \Sigma)\)</span>, not the sampling
distribution of our quantity of interest.</li>
</ul>
<p>So how can we get there?</p>
<ul>
<li>Beyond OLS, deriving the sampling distribution of quantities of
interest analytically is rather painful.</li>
<li>Analytical normal-approximation confidence intervals are also
imprecise when the asymptotic properties of estimators do not hold in
finite samples (e.g., 95% confidence intervals that include predicted
probabilities outside of <span class="math inline">\([0,
1]\)</span>).</li>
<li>So we will use a flexible approach that allows us to get sampling
distributions for <em>any</em> quantity of interest: <strong>Parameter
simulation</strong>.</li>
</ul>
</div>
<div id="section-the-algorithm" class="section level3">
<h3>The algorithm</h3>
<p>The algorithm presented by <a
href="https://gking.harvard.edu/files/gking/files/making.pdf">King et
al. (2000)</a> contains five steps:</p>
<ol style="list-style-type: decimal">
<li>Simulate the sampling distribution of the model parameters by taking
<span class="math inline">\(S\)</span> draws from <span
class="math inline">\(\beta \sim \text{MVN}(\hat\beta, \hat
\Sigma)\)</span></li>
<li>Choose a <em>covariate scenario</em>, i.e., specify a vector <span
class="math inline">\(\mathbf{x^{\ast}}\)</span> or a matrix <span
class="math inline">\(\mathbf{X^{\ast}}\)</span>.</li>
<li>For each simulation <span class="math inline">\(\beta^{s}\)</span>
for <span class="math inline">\(s=1,...,S\)</span>, calculate <span
class="math inline">\(\theta^{s} = g^{-1}(\mathbf{x^{\ast}}^{\prime}
\beta^{s})\)</span>.</li>
</ol>
<p>Whenever <span class="math inline">\(\theta\)</span> gives a direct
estimate of <span
class="math inline">\(\mathbb{E}[y|\mathbf{x^{\ast}}]\)</span>, these
three steps will be sufficient!</p>
<p>In some instances involving non-symmetrical transformations, we need
to go the extra mile:</p>
<ol start="4" style="list-style-type: decimal">
<li>Simulate the predictive distribution <span
class="math inline">\(M\)</span> times for each simulation <span
class="math inline">\(\theta^{s}\)</span>.</li>
<li>Average over the <span class="math inline">\(M\)</span> predictive
draws within each simulation <span
class="math inline">\(s\)</span>.</li>
</ol>
<p>We will <em>not</em> cover any such examples. So in our upcoming
applied logistic regression example, we can produce inferential
uncertainty with the simpler three-step algorithm.</p>
<p>You can easily see why this the case: The expected value of a
Bernoulli distribution with parameter <span
class="math inline">\(\pi\)</span> is <span
class="math inline">\(\pi\)</span> itself: <span
class="math inline">\(\mathbb{E}[\text{Bernoulli}(\pi)] = \pi\)</span>.
So drawing many 0’s and 1’s in step 4 just to average them back to a
proportion that will be (approximately) equal to <span
class="math inline">\(\pi\)</span> is redundant.</p>
<p>
<script type="application/shiny-prerendered" data-context="server-start">
## --- learnr ---
if ("learnr" %in% (.packages()))
  detach(package:learnr, unload = TRUE)
library(learnr)
knitr::opts_chunk$set(echo = FALSE)

## ---- CRAN Packages ----
## Save package names as a vector of strings
pkgs <-  c()

## Install uninstalled packages
lapply(pkgs[!(pkgs %in% installed.packages())], 
       install.packages,
       repos='http://cran.us.r-project.org')

## Load all packages to library and adjust options
lapply(pkgs, library, character.only = TRUE)

## ---- GitHub Packages ----


## ---- Global learnr Objects ----

</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::register_http_handlers(session, metadata = NULL)
</script>


<script type="application/shiny-prerendered" data-context="server">
learnr:::prepare_tutorial_state(session)
</script>
 
<script type="application/shiny-prerendered" data-context="server">
learnr:::i18n_observe_tutorial_language(input, session)
</script>


<script type="application/shiny-prerendered" data-context="server">
session$onSessionEnded(function() {
        learnr:::event_trigger(session, "session_stop")
      })
</script>
</p>
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="dependencies">
{"type":"list","attributes":{},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["header-attrs"]},{"type":"character","attributes":{},"value":["2.17"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pandoc"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["header-attrs.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.17"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootstrap"]},{"type":"character","attributes":{},"value":["3.3.5"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/bootstrap"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["viewport"]}},"value":[{"type":"character","attributes":{},"value":["width=device-width, initial-scale=1"]}]},{"type":"character","attributes":{},"value":["js/bootstrap.min.js","shim/html5shiv.min.js","shim/respond.min.js"]},{"type":"character","attributes":{},"value":["css/cerulean.min.css"]},{"type":"character","attributes":{},"value":["<style>h1 {font-size: 34px;}\n       h1.title {font-size: 38px;}\n       h2 {font-size: 30px;}\n       h3 {font-size: 24px;}\n       h4 {font-size: 18px;}\n       h5 {font-size: 16px;}\n       h6 {font-size: 12px;}\n       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}\n       pre:not([class]) { background-color: white }<\/style>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.17"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["pagedtable"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/pagedtable-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["js/pagedtable.js"]},{"type":"character","attributes":{},"value":["css/pagedtable.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.17"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["textmate.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.17"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.11.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["i18n"]},{"type":"character","attributes":{},"value":["21.6.10"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/i18n"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["i18next.min.js","tutorial-i18n-init.js"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["<script id=\"i18n-cstm-trns\" type=\"application/json\">{\"language\":\"en\",\"resources\":{\"en\":{\"translation\":{\"button\":{\"runcode\":\"Run Code\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Hint\",\"hint_plural\":\"Hints\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Next Hint\",\"hintprev\":\"Previous Hint\",\"solution\":\"Solution\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copy to Clipboard\",\"startover\":\"Start Over\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continue\",\"submitanswer\":\"Submit Answer\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Previous Topic\",\"nexttopic\":\"Next Topic\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Try Again\"},\"text\":{\"startover\":\"Start Over\",\"areyousure\":\"Are you sure you want to start over? (all exercise progress will be reset)\",\"youmustcomplete\":\"You must complete the\",\"exercise\":\"exercise\",\"exercise_plural\":\"exercises\",\"inthissection\":\"in this section before continuing.\",\"code\":\"Code\",\"enginecap\":\"{{engine}} $t(text.code)\",\"quiz\":\"Quiz\",\"blank\":\"blank\",\"blank_plural\":\"blanks\",\"exercisecontainsblank\":\"This exercise contains {{count}} $t(text.blank).\",\"pleasereplaceblank\":\"Please replace {{blank}} with valid code.\",\"unparsable\":\"It looks like this might not be valid R code. R cannot determine how to turn your text into a complete command. You may have forgotten to fill in a blank, to remove an underscore, to include a comma between arguments, or to close an opening <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> or <code>{<\\/code> with a matching <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> or <code>}<\\/code>.\\n\",\"unparsablequotes\":\"<p>It looks like your R code contains specially formatted quotation marks or &quot;curly&quot; quotes (<code>{{character}}<\\/code>) around character strings, making your code invalid. R requires character values to be contained in straight quotation marks (<code>&quot;<\\/code> or <code>'<\\/code>).<\\/p> {{code}} <p>Don't worry, this is a common source of errors when you copy code from another app that applies its own formatting to text. You can try replacing the code on that line with the following. There may be other places that need to be fixed, too.<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>It looks like your R code contains an unexpected special character (<code>{{character}}<\\/code>) that makes your code invalid.<\\/p> {{code}} <p>Sometimes your code may contain a special character that looks like a regular character, especially if you copy and paste the code from another app. Try deleting the special character from your code and retyping it manually.<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>It looks like your R code contains an unexpected special character (<code>{{character}}<\\/code>) that makes your code invalid.<\\/p> {{code}} <p>Sometimes your code may contain a special character that looks like a regular character, especially if you copy and paste the code from another app. You can try replacing the code on that line with the following. There may be other places that need to be fixed, too.<\\/p> {{suggestion}}\\n\",\"and\":\"and\",\"or\":\"or\",\"listcomma\":\", \",\"oxfordcomma\":\",\"}}},\"fr\":{\"translation\":{\"button\":{\"runcode\":\"Lancer le Code\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Indication\",\"hint_plural\":\"Indications\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Indication Suivante\",\"hintprev\":\"Indication Précédente\",\"solution\":\"Solution\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copier dans le Presse-papier\",\"startover\":\"Recommencer\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuer\",\"submitanswer\":\"Soumettre\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Chapitre Précédent\",\"nexttopic\":\"Chapitre Suivant\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Réessayer\"},\"text\":{\"startover\":\"Recommencer\",\"areyousure\":\"Êtes-vous certains de vouloir recommencer? (La progression sera remise à zéro)\",\"youmustcomplete\":\"Vous devez d'abord compléter\",\"exercise\":\"l'exercice\",\"exercise_plural\":\"des exercices\",\"inthissection\":\"de cette section avec de continuer.\",\"code\":\"Code\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"and\":\"et\",\"or\":\"ou\",\"oxfordcomma\":\"\"}}},\"es\":{\"translation\":{\"button\":{\"runcode\":\"Ejecutar código\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Pista\",\"hint_plural\":\"Pistas\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Siguiente pista\",\"hintprev\":\"Pista anterior\",\"solution\":\"Solución\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copiar al portapapeles\",\"startover\":\"Reiniciar\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuar\",\"submitanswer\":\"Enviar respuesta\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Tema anterior\",\"nexttopic\":\"Tema siguiente\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Volver a intentar\"},\"text\":{\"startover\":\"Reiniciar\",\"areyousure\":\"¿De verdad quieres empezar de nuevo? (todo el progreso del ejercicio se perderá)\",\"youmustcomplete\":\"Debes completar\",\"exercise\":\"el ejercicio\",\"exercise_plural\":\"los ejercicios\",\"inthissection\":\"en esta sección antes de continuar.\",\"code\":\"Código\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Cuestionario\",\"and\":\"y\",\"or\":\"o\",\"oxfordcomma\":\"\"}}},\"pt\":{\"translation\":{\"button\":{\"runcode\":\"Executar código\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Dica\",\"hint_plural\":\"Dicas\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Próxima dica\",\"hintprev\":\"Dica anterior\",\"solution\":\"Solução\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Copiar para a área de transferência\",\"startover\":\"Reiniciar\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Continuar\",\"submitanswer\":\"Enviar resposta\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Tópico anterior\",\"nexttopic\":\"Próximo tópico\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Tentar novamente\"},\"text\":{\"startover\":\"Reiniciar\",\"areyousure\":\"Tem certeza que deseja começar novamente? (todo o progresso feito será perdido)\",\"youmustcomplete\":\"Você deve completar\",\"exercise\":\"o exercício\",\"exercise_plural\":\"os exercícios\",\"inthissection\":\"nesta seção antes de continuar.\",\"code\":\"Código\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"and\":\"e\",\"or\":\"ou\",\"oxfordcomma\":\"\"}}},\"tr\":{\"translation\":{\"button\":{\"runcode\":\"Çalistirma Kodu\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Ipucu\",\"hint_plural\":\"Ipuçlari\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Sonraki Ipucu\",\"hintprev\":\"Önceki Ipucu\",\"solution\":\"Çözüm\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Pano'ya Kopyala\",\"startover\":\"Bastan Baslamak\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Devam et\",\"submitanswer\":\"Cevabi onayla\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Önceki Konu\",\"nexttopic\":\"Sonraki Konu\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Tekrar Deneyin\"},\"text\":{\"startover\":\"Bastan Baslamak\",\"areyousure\":\"Bastan baslamak istediginizden emin misiniz? (tüm egzersiz ilerlemesi kaybolacak)\",\"youmustcomplete\":\"Tamamlamalisin\",\"exercise\":\"egzersiz\",\"exercise_plural\":\"egzersizler\",\"inthissection\":\"devam etmeden önce bu bölümde\",\"code\":\"Kod\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Sinav\",\"oxfordcomma\":\"\"}}},\"emo\":{\"translation\":{\"button\":{\"runcode\":\"<U+0001F3C3>\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"<U+0001F4A1>\",\"hint_plural\":\"$t(button.hint)\",\"hinttitle\":\"$t(button.hint)\",\"solution\":\"<U+0001F3AF>\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"<U+0001F4CB>\",\"startover\":\"<U+23EE>\",\"startovertitle\":\"Start Over\",\"continue\":\"<U+2705>\",\"submitanswer\":\"<U+0001F197>\",\"submitanswertitle\":\"Submit Answer\",\"previoustopic\":\"<U+2B05>\",\"nexttopic\":\"<U+27A1>\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"<U+0001F501>\"},\"text\":{\"startover\":\"<U+23EE>\",\"areyousure\":\"<U+0001F914>\",\"youmustcomplete\":\"<U+26A0><U+FE0F> <U+0001F449> <U+0001F9D1><U+200D><U+0001F4BB>\",\"exercise\":\"\",\"exercise_plural\":\"\",\"inthissection\":\"\",\"code\":\"<U+0001F4BB>\",\"enginecap\":\"$t(text.code) {{engine}}\",\"oxfordcomma\":\"\"}}},\"eu\":{\"translation\":{\"button\":{\"runcode\":\"Kodea egikaritu\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Laguntza\",\"hint_plural\":\"Laguntza\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Aurreko laguntza\",\"hintprev\":\"Hurrengo laguntza\",\"solution\":\"Ebazpena\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Arbelean kopiatu\",\"startover\":\"Berrabiarazi\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Jarraitu\",\"submitanswer\":\"Erantzuna bidali\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Aurreko atala\",\"nexttopic\":\"Hurrengo atala\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Berriro saiatu\"},\"text\":{\"startover\":\"Berrabiarazi\",\"areyousure\":\"Berriro hasi nahi duzu? (egindako lana galdu egingo da)\",\"youmustcomplete\":\"Aurrera egin baino lehen atal honetako\",\"exercise\":\"ariketa egin behar duzu.\",\"exercise_plural\":\"ariketak egin behar dituzu.\",\"inthissection\":\"\",\"code\":\"Kodea\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Galdetegia\",\"oxfordcomma\":\"\"}}},\"de\":{\"translation\":{\"button\":{\"runcode\":\"Code ausführen\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Tipp\",\"hint_plural\":\"Tipps\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Nächster Tipp\",\"hintprev\":\"Vorheriger Tipp\",\"solution\":\"Lösung\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"In die Zwischenablage kopieren\",\"startover\":\"Neustart\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Weiter\",\"submitanswer\":\"Antwort einreichen\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Vorheriges Kapitel\",\"nexttopic\":\"Nächstes Kapitel\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Nochmal versuchen\"},\"text\":{\"startover\":\"Neustart\",\"areyousure\":\"Bist du sicher, dass du neustarten willst? (der gesamte Lernfortschritt wird gelöscht)\",\"youmustcomplete\":\"Vervollstädinge\",\"exercise\":\"die Übung\",\"exercise_plural\":\"die Übungen\",\"inthissection\":\"in diesem Kapitel, bevor du fortfährst.\",\"code\":\"Code\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"blank\":\"Lücke\",\"blank_plural\":\"Lücken\",\"pleasereplaceblank\":\"Bitte ersetze {{blank}} mit gültigem Code.\",\"unparsable\":\"Dies scheint kein gültiger R Code zu sein. R kann deinen Text nicht in einen gültigen Befehl übersetzen. Du hast vielleicht vergessen, die Lücke zu füllen, einen Unterstrich zu entfernen, ein Komma zwischen Argumente zu setzen oder ein eröffnendes <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> oder <code>{<\\/code> mit einem zugehörigen <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> oder <code>}<\\/code> zu schließen.\\n\",\"and\":\"und\",\"or\":\"oder\",\"listcomma\":\", \",\"oxfordcomma\":\",\"}}},\"ko\":{\"translation\":{\"button\":{\"runcode\":\"<U+CF54><U+B4DC> <U+C2E4><U+D589>\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"<U+D78C><U+D2B8>\",\"hint_plural\":\"<U+D78C><U+D2B8><U+B4E4>\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"<U+B2E4><U+C74C> <U+D78C><U+D2B8>\",\"hintprev\":\"<U+C774><U+C804> <U+D78C><U+D2B8>\",\"solution\":\"<U+C194><U+B8E8><U+C158>\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"<U+D074><U+B9BD><U+BCF4><U+B4DC><U+C5D0> <U+BCF5><U+C0AC>\",\"startover\":\"<U+C7AC><U+D559><U+C2B5>\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"<U+B2E4><U+C74C> <U+D559><U+C2B5><U+C73C><U+B85C>\",\"submitanswer\":\"<U+C815><U+B2F5> <U+C81C><U+CD9C>\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"<U+C774><U+C804> <U+D1A0><U+D53D>\",\"nexttopic\":\"<U+B2E4><U+C74C> <U+D1A0><U+D53D>\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"<U+C7AC><U+C2DC><U+B3C4>\"},\"text\":{\"startover\":\"<U+C7AC><U+D559><U+C2B5>\",\"areyousure\":\"<U+B2E4><U+C2DC> <U+C2DC><U+C791> <U+D558><U+C2DC><U+ACA0><U+C2B5><U+B2C8><U+AE4C>? (<U+BAA8><U+B4E0> <U+C608><U+C81C><U+C758> <U+C9C4><U+D589> <U+C815><U+BCF4><U+AC00> <U+C7AC><U+C124><U+C815><U+B429><U+B2C8><U+B2E4>)\",\"youmustcomplete\":\"<U+B2F9><U+C2E0><U+C740> <U+C644><U+B8CC><U+D574><U+C57C> <U+D569><U+B2C8><U+B2E4>\",\"exercise\":\"<U+C5F0><U+C2B5><U+BB38><U+C81C>\",\"exercise_plural\":\"<U+C5F0><U+C2B5><U+BB38><U+C81C><U+B4E4>\",\"inthissection\":\"<U+C774> <U+C139><U+C158><U+C744> <U+C2E4><U+D589><U+D558><U+AE30> <U+C804><U+C5D0>\",\"code\":\"<U+CF54><U+B4DC>\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"<U+D034><U+C988>\",\"blank\":\"<U+ACF5><U+BC31>\",\"blank_plural\":\"<U+ACF5><U+BC31><U+B4E4>\",\"exercisecontainsblank\":\"<U+C774> <U+C5F0><U+C2B5><U+BB38><U+C81C><U+C5D0><U+B294> {{count}}<U+AC1C><U+C758> $t(text.blank)<U+C774> <U+D3EC><U+D568><U+B418><U+C5B4> <U+C788><U+C2B5><U+B2C8><U+B2E4>.\",\"pleasereplaceblank\":\"{{blank}}<U+B97C> <U+C720><U+D6A8><U+D55C> <U+CF54><U+B4DC><U+B85C> <U+BC14><U+AFB8><U+C2ED><U+C2DC><U+C624>.\",\"unparsable\":\"<U+C774><U+AC83><U+C740> <U+C720><U+D6A8><U+D55C> R <U+CF54><U+B4DC><U+AC00> <U+C544><U+B2D0> <U+C218> <U+C788><U+C2B5><U+B2C8><U+B2E4>. R<U+C740> <U+D14D><U+C2A4><U+D2B8><U+B97C> <U+C644><U+C804><U+D55C> <U+BA85><U+B839><U+C73C><U+B85C> <U+BCC0><U+D658><U+D558><U+B294> <U+BC29><U+BC95><U+C744> <U+ACB0><U+C815><U+D560> <U+C218> <U+C5C6><U+C2B5><U+B2C8><U+B2E4>. <U+B2F9><U+C2E0><U+C740> <U+ACF5><U+BC31><U+C774><U+B098> <U+BC11><U+C904><U+C744> <U+B300><U+CCB4><U+D558><U+C5EC> <U+CC44><U+C6B0><U+AE30>, <U+C778><U+C218><U+B97C> <U+CEF4><U+B9C8><U+B85C> <U+AD6C><U+BD84><U+D558><U+AE30>, <U+B610><U+B294> <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> , <code>{<\\/code><U+B85C> <U+C2DC><U+C791><U+D558><U+B294> <U+AD6C><U+BB38><U+C744> <U+B2EB><U+B294> <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code>, <code>}<\\/code><U+C744> <U+C78A><U+C5C8><U+C744> <U+C218><U+B3C4> <U+C788><U+C2B5><U+B2C8><U+B2E4>.\\n\",\"and\":\"<U+ADF8><U+B9AC><U+ACE0>\",\"or\":\"<U+D639><U+C740>\",\"listcomma\":\", \",\"oxfordcomma\":\"\"}}},\"zh\":{\"translation\":{\"button\":{\"runcode\":\"<U+8FD0><U+884C><U+4EE3><U+7801>\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"<U+63D0><U+793A>\",\"hint_plural\":\"<U+63D0><U+793A>\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"<U+4E0B><U+4E00><U+4E2A><U+63D0><U+793A>\",\"hintprev\":\"<U+4E0A><U+4E00><U+4E2A><U+63D0><U+793A>\",\"solution\":\"<U+7B54><U+6848>\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"<U+590D><U+5236><U+5230><U+526A><U+5207><U+677F>\",\"startover\":\"<U+91CD><U+65B0><U+5F00><U+59CB>\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"<U+7EE7><U+7EED>\",\"submitanswer\":\"<U+63D0><U+4EA4><U+7B54><U+6848>\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"<U+4E0A><U+4E00><U+4E13><U+9898>\",\"nexttopic\":\"<U+4E0B><U+4E00><U+4E13><U+9898>\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"<U+518D><U+8BD5><U+4E00><U+6B21>\"},\"text\":{\"startover\":\"<U+91CD><U+7F6E>\",\"areyousure\":\"<U+4F60><U+786E><U+5B9A><U+8981><U+91CD><U+65B0><U+5F00><U+59CB><U+5417>? (<U+6240><U+6709><U+5F53><U+524D><U+8FDB><U+5EA6><U+5C06><U+88AB><U+91CD><U+7F6E>)\",\"youmustcomplete\":\"<U+4F60><U+5FC5><U+987B><U+5B8C><U+6210>\",\"exercise\":\"<U+7EC3><U+4E60>\",\"exercise_plural\":\"<U+7EC3><U+4E60>\",\"inthissection\":\"<U+5728><U+8FDB><U+884C><U+672C><U+8282><U+4E4B><U+524D>\",\"code\":\"<U+4EE3><U+7801>\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"<U+6D4B><U+8BD5>\",\"blank\":\"<U+7A7A>\",\"blank_plural\":\"<U+7A7A>\",\"exercisecontainsblank\":\"<U+672C><U+7EC3><U+4E60><U+5305><U+542B>{{count}}<U+4E2A>$t(text.blank)\",\"pleasereplaceblank\":\"<U+8BF7><U+5728>{{blank}}<U+5185><U+586B><U+5199><U+6070><U+5F53><U+7684><U+4EE3><U+7801>\",\"unparsable\":\"<U+8FD9><U+4F3C><U+4E4E><U+4E0D><U+662F><U+6709><U+6548><U+7684>R<U+4EE3><U+7801><U+3002> R<U+4E0D><U+77E5><U+9053><U+5982><U+4F55><U+5C06><U+60A8><U+7684><U+6587><U+672C><U+8F6C><U+6362><U+4E3A><U+5B8C><U+6574><U+7684><U+547D><U+4EE4><U+3002> <U+60A8><U+662F><U+5426><U+5FD8><U+4E86><U+586B><U+7A7A>,<U+5FD8><U+4E86><U+5220><U+9664><U+4E0B><U+5212><U+7EBF>,<U+5FD8><U+4E86><U+5728><U+53C2><U+6570><U+4E4B><U+95F4><U+5305><U+542B><U+9017><U+53F7>,<U+6216><U+8005><U+662F><U+5FD8><U+4E86><U+7528><code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code>,<code>}<\\/code><U+6765><U+5C01><U+95ED><code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code><U+3002> or <code>{<\\/code><U+3002>\\n\",\"unparsablequotes\":\"<p><U+60A8><U+7684>R<U+4EE3><U+7801><U+4E2D><U+4F3C><U+4E4E><U+542B><U+6709><U+7279><U+6B8A><U+683C><U+5F0F><U+7684><U+5F15><U+53F7>,<U+6216><U+8005><U+5F2F><U+5F15><U+53F7>(<code>{{character}}<\\/code>) <U+5728><U+5B57><U+7B26><U+4E32><U+524D><U+540E>,<U+5728>R<U+4E2D><U+5B57><U+7B26><U+4E32><U+5E94><U+8BE5><U+88AB><U+76F4><U+5F15><U+53F7>(<code>&quot;<\\/code> <U+6216><U+8005> <code>'<\\/code>)<U+5305><U+88F9><U+3002><\\/p> {{code}} <p><U+522B><U+62C5><U+5FC3>,<U+8BE5><U+9519><U+8BEF><U+7ECF><U+5E38><U+5728><U+590D><U+5236><U+7C98><U+8D34><U+5305><U+542B><U+683C><U+5F0F><U+7684><U+4EE3><U+7801><U+65F6><U+9047><U+5230>, <U+60A8><U+53EF><U+4EE5><U+5C1D><U+8BD5><U+5C06><U+8BE5><U+884C><U+4E2D><U+7684><U+4EE3><U+7801><U+66FF><U+6362><U+4E3A><U+4EE5><U+4E0B><U+4EE3><U+7801>,<U+4E5F><U+8BB8><U+8FD8><U+6709><U+5176><U+4ED6><U+5730><U+65B9><U+9700><U+8981><U+4FEE><U+6539><U+3002><\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p><U+60A8><U+7684><U+4EE3><U+7801><U+4E2D><U+4F3C><U+4E4E><U+5305><U+542B><U+6709><U+5F02><U+5E38><U+5B57><U+7B26>(<code>{{character}}<\\/code>),<U+5BFC><U+81F4><U+4EE3><U+7801><U+65E0><U+6548><U+3002><\\/p> {{code}} <p><U+6709><U+65F6><U+5019><U+4F60><U+7684><U+4EE3><U+7801><U+53EF><U+80FD><U+542B><U+6709><U+770B><U+4F3C><U+6B63><U+5E38><U+5B57><U+7B26><U+7684><U+7279><U+6B8A><U+5B57><U+7B26>,<U+7279><U+522B><U+662F><U+5F53><U+4F60><U+590D><U+5236><U+7C98><U+8D34><U+5176><U+4ED6><U+6765><U+6E90><U+4EE3><U+7801><U+7684><U+65F6><U+5019><U+3002> <U+8BF7><U+8BD5><U+7740><U+5220><U+9664><U+8FD9><U+4E9B><U+7279><U+6B8A><U+5B57><U+7B26>,<U+91CD><U+65B0><U+8F93><U+5165><\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p><U+60A8><U+7684><U+4EE3><U+7801><U+4E2D><U+4F3C><U+4E4E><U+5305><U+542B><U+6709><U+5F02><U+5E38><U+5B57><U+7B26>(<code>{{character}}<\\/code>),<U+5BFC><U+81F4><U+4EE3><U+7801><U+65E0><U+6548><U+3002><\\/p> {{code}} <p><U+6709><U+65F6><U+5019><U+4F60><U+7684><U+4EE3><U+7801><U+53EF><U+80FD><U+542B><U+6709><U+770B><U+4F3C><U+6B63><U+5E38><U+5B57><U+7B26><U+7684><U+7279><U+6B8A><U+5B57><U+7B26>,<U+7279><U+522B><U+662F><U+5F53><U+4F60><U+590D><U+5236><U+7C98><U+8D34><U+5176><U+4ED6><U+6765><U+6E90><U+4EE3><U+7801><U+7684><U+65F6><U+5019><U+3002> <U+8BF7><U+8BD5><U+7740><U+5220><U+9664><U+8FD9><U+4E9B><U+7279><U+6B8A><U+5B57><U+7B26>,<U+91CD><U+65B0><U+8F93><U+5165><\\/p>\\n\",\"and\":\"<U+4E14>\",\"or\":\"<U+6216>\",\"listcomma\":\",\",\"oxfordcomma\":\",\"}}},\"pl\":{\"translation\":{\"button\":{\"runcode\":\"Uruchom kod\",\"runcodetitle\":\"$t(button.runcode) ({{kbd}})\",\"hint\":\"Podpowiedz\",\"hint_plural\":\"Podpowiedzi\",\"hinttitle\":\"$t(button.hint)\",\"hintnext\":\"Nastepna podpowiedz\",\"hintprev\":\"Poprzednia podpowiedz\",\"solution\":\"Rozwiazanie\",\"solutiontitle\":\"$t(button.solution)\",\"copyclipboard\":\"Kopiuj do schowka\",\"startover\":\"Zacznij od poczatku\",\"startovertitle\":\"$t(button.startover)\",\"continue\":\"Kontynuuj\",\"submitanswer\":\"Wyslij\",\"submitanswertitle\":\"$t(button.submitanswer)\",\"previoustopic\":\"Poprzednia sekcja\",\"nexttopic\":\"Nastepna sekcja\",\"questionsubmit\":\"$t(button.submitanswer)\",\"questiontryagain\":\"Spróbuj ponownie\"},\"text\":{\"startover\":\"Zacznij od poczatku\",\"areyousure\":\"Czy na pewno chcesz zaczac od poczatku? (caly postep w zadaniu zostanie utracony)\",\"youmustcomplete\":\"Musisz ukonczyc\",\"exercise\":\"cwiczenie\",\"exercise_plural\":\"cwiczenia\",\"inthissection\":\"w tej sekcji przed kontynuowaniem\",\"code\":\"Kod\",\"enginecap\":\"$t(text.code) {{engine}}\",\"quiz\":\"Quiz\",\"blank\":\"luka\",\"blank_plural\":\"luk(i)\",\"exercisecontainsblank\":\"To cwiczenie zawiera {{count}} $t(text.blank).\",\"pleasereplaceblank\":\"Prosze uzupelnic {{blank}} prawidlowym kodem.\",\"unparsable\":\"Wyglada na to, ze moze to nie byc prawidlowy kod R. R nie jest w stanie przetworzyc Twojego tekstu na polecenie. Mogles(-as) zapomniec wypelnic luki, usunac podkreslnik, umiescic przecinka miedzy argumentami, lub zamknac znak <code>&quot;<\\/code>, <code>'<\\/code>, <code>(<\\/code> lub <code>{<\\/code> odpowiadajacym <code>&quot;<\\/code>, <code>'<\\/code>, <code>)<\\/code> lub <code>}<\\/code>.\\n\",\"unparsablequotes\":\"<p>Wyglada na to, ze Twój kod zawiera szczególnie sformatowane cudzyslowy lub cudzyslowy typograficzne (<code>{{character}}<\\/code>) przy ciagach znaków, co sprawia, ze kod jest niepoprawny. R wymaga cudzyslowów prostych (<code>&quot;<\\/code> albo <code>'<\\/code>).<\\/p> {{code}} <p>Nie martw sie, to powszechne zródlo bledów, gdy kopiuje sie kod z innego programu, który sam formatuje teskt. Mozesz spróbowac zastapic swój kod nastepujacym kodem. Moga byc tez inne miejsca, które wymagaja poprawienia.<\\/p> {{suggestion}}\\n\",\"unparsableunicode\":\"<p>Wyglada na to, ze Twój kod zawiera niespodziewany znak specjalny (<code>{{character}}<\\/code>), co sprawia, ze kod jest niepoprawny.<\\/p> {{code}} <p>Czasami Twój kod moze zawierac znak specjalny, który wyglada jak zwykly znak, zwlaszcza jesli kopiujesz kod z innego programu. Spróbuj usunac znak specjalny i wpisac do ponownie recznie.<\\/p>\\n\",\"unparsableunicodesuggestion\":\"<p>Wyglada na to, ze Twój kod zawiera niespodziewany znak specjalny (<code>{{character}}<\\/code>), co sprawia, ze kod jest niepoprawny.<\\/p> {{code}} <p>Czasami Twój kod moze zawierac znak specjalny, który wyglada jak zwykly znak, zwlaszcza jesli kopiujesz kod z innego programu. Mozesz spróbowac zastapic swój kod nastepujacym kodem. Moga byc tez inne miejsca, które wymagaja poprawienia.<\\/p> {{suggestion}}\\n\",\"and\":\"i\",\"or\":\"lub\",\"listcomma\":\", \",\"oxfordcomma\":\"\"}}}}}<\/script>"]},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial-format"]},{"type":"character","attributes":{},"value":["0.11.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmarkdown/templates/tutorial/resources"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial-format.js"]},{"type":"character","attributes":{},"value":["tutorial-format.css","rstudio-theme.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["navigation"]},{"type":"character","attributes":{},"value":["1.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/navigation-1.1"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tabsets.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.17"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["highlightjs"]},{"type":"character","attributes":{},"value":["9.12.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/highlightjs"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["highlight.js"]},{"type":"character","attributes":{},"value":["default.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.17"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["jquery"]},{"type":"character","attributes":{},"value":["3.6.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/3.6.0"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquery-3.6.0.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["jquerylib"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.1.4"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["font-awesome"]},{"type":"character","attributes":{},"value":["5.1.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["rmd/h/fontawesome"]}]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["css/all.css","css/v4-shims.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["rmarkdown"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["2.17"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["bootbox"]},{"type":"character","attributes":{},"value":["5.5.2"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/bootbox"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["bootbox.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["idb-keyvalue"]},{"type":"character","attributes":{},"value":["3.2.0"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/idb-keyval"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["idb-keyval-iife-compat.min.js"]},{"type":"NULL"},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[false]},{"type":"character","attributes":{},"value":["0.11.1"]}]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["name","version","src","meta","script","stylesheet","head","attachment","package","all_files","pkgVersion"]},"class":{"type":"character","attributes":{},"value":["html_dependency"]}},"value":[{"type":"character","attributes":{},"value":["tutorial"]},{"type":"character","attributes":{},"value":["0.11.1"]},{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["file"]}},"value":[{"type":"character","attributes":{},"value":["lib/tutorial"]}]},{"type":"NULL"},{"type":"character","attributes":{},"value":["tutorial.js"]},{"type":"character","attributes":{},"value":["tutorial.css"]},{"type":"NULL"},{"type":"NULL"},{"type":"character","attributes":{},"value":["learnr"]},{"type":"logical","attributes":{},"value":[true]},{"type":"character","attributes":{},"value":["0.11.1"]}]}]}
</script>
<!--/html_preserve-->
<!--html_preserve-->
<script type="application/shiny-prerendered" data-context="execution_dependencies">
{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages"]}},"value":[{"type":"list","attributes":{"names":{"type":"character","attributes":{},"value":["packages","version"]},"class":{"type":"character","attributes":{},"value":["data.frame"]},"row.names":{"type":"integer","attributes":{},"value":[1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46]}},"value":[{"type":"character","attributes":{},"value":["backports","base","bslib","cachem","checkmate","cli","compiler","curl","datasets","digest","ellipsis","evaluate","fastmap","graphics","grDevices","htmltools","htmlwidgets","httpuv","jquerylib","jsonlite","knitr","later","learnr","lifecycle","magrittr","markdown","methods","mime","promises","R6","Rcpp","rlang","rmarkdown","rprojroot","rstudioapi","sass","shiny","stats","stringi","stringr","tools","utils","withr","xfun","xtable","yaml"]},{"type":"character","attributes":{},"value":["1.4.1","4.2.1","0.4.1","1.0.6","2.1.0","3.4.0","4.2.1","4.3.2","4.2.1","0.6.29","0.3.2","0.18","1.1.0","4.2.1","4.2.1","0.5.3","1.5.4","1.6.6","0.1.4","1.8.0","1.40","1.3.0","0.11.1","1.0.3","2.0.3","1.3","4.2.1","0.12","1.2.0.1","2.5.1","1.0.9","1.0.6","2.17","2.0.3","0.14","0.4.2","1.7.3","4.2.1","1.7.8","1.4.1","4.2.1","4.2.1","2.5.0","0.33","1.8-4","2.3.5"]}]}]}
</script>
<!--/html_preserve-->
</div>
</div>

</article> <!-- topics -->

<div class="topicsContainer">
<div class="topicsPositioner">
<div class="band">
<div class="bandContent topicsListContainer">

<!-- begin doc-metadata -->
<div id="doc-metadata">
<h1 class="title toc-ignore" style="display:none;">Lecture: Generalized
Linear Models</h1>
</div>
<!-- end doc-metadata -->

</div> <!-- bandContent.topicsListContainer -->
</div> <!-- band -->
</div> <!-- topicsPositioner -->
</div> <!-- topicsContainer -->


</main> <!-- bandContent page -->
</div> <!-- pageContent band -->



<!-- Build Tabsets -->
<script>
$(document).ready(function () {
  window.buildTabsets("section-TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<script>
// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});
</script>


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>


</body>

</html>
